{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:05:54.241887Z",
     "start_time": "2024-05-26T04:05:54.234149Z"
    }
   },
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();\n",
    "\n",
    "const process = {\n",
    "    env\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:05:57.919695Z",
     "start_time": "2024-05-26T04:05:54.248856Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage {\n",
       "  lc_serializable: \u001b[33mtrue\u001b[39m,\n",
       "  lc_kwargs: {\n",
       "    content: \u001b[32m\"Why did the scarecrow win an award? Because he was outstanding in his field!\"\u001b[39m,\n",
       "    tool_calls: [],\n",
       "    invalid_tool_calls: [],\n",
       "    additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "    response_metadata: {}\n",
       "  },\n",
       "  lc_namespace: [ \u001b[32m\"langchain_core\"\u001b[39m, \u001b[32m\"messages\"\u001b[39m ],\n",
       "  content: \u001b[32m\"Why did the scarecrow win an award? Because he was outstanding in his field!\"\u001b[39m,\n",
       "  name: \u001b[90mundefined\u001b[39m,\n",
       "  additional_kwargs: { function_call: \u001b[90mundefined\u001b[39m, tool_calls: \u001b[90mundefined\u001b[39m },\n",
       "  response_metadata: {\n",
       "    tokenUsage: { completionTokens: \u001b[33m17\u001b[39m, promptTokens: \u001b[33m11\u001b[39m, totalTokens: \u001b[33m28\u001b[39m },\n",
       "    finish_reason: \u001b[32m\"stop\"\u001b[39m\n",
       "  },\n",
       "  tool_calls: [],\n",
       "  invalid_tool_calls: []\n",
       "}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const model = new ChatOpenAI(\n",
    "    {\n",
    "        configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "    }\n",
    ");\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "//const model = new ChatOpenAI();\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "});\n",
    "\n",
    "await model.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StringOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new StringOutputParser();\n",
    "//const model = new ChatOpenAI();\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "});\n",
    "\n",
    "const chain = model.pipe(parser)\n",
    "\n",
    "await chain.invoke([\n",
    "    new HumanMessage(\"Tell me a joke\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { StructuredOutputParser } from \"langchain/output_parsers\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "\n",
    "const parser = StructuredOutputParser.fromNamesAndDescriptions({\n",
    "  answer: \"用户问题的答案\",\n",
    "  evidence: \"你回答用户问题所依据的答案\",\n",
    "  confidence: \"问题答案的可信度评分，格式是百分数\",\n",
    "});\n",
    "\n",
    "console.log(parser.getFormatInstructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const prompt = PromptTemplate.fromTemplate(\"尽可能的回答用的问题 \\n{instructions} \\n{question}\")\n",
    "//const model = new ChatOpenAI();\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(model).pipe(parser)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const res = await chain.invoke({\n",
    "    question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { CommaSeparatedListOutputParser } from \"@langchain/core/output_parsers\";\n",
    "\n",
    "const parser = new CommaSeparatedListOutputParser();\n",
    "\n",
    "console.log(parser.getFormatInstructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//const model = new ChatOpenAI();\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "});\n",
    "const prompt = PromptTemplate.fromTemplate(\"列出3个 {country} 的着名的互联网公司.\\n{instructions}\")\n",
    "    \n",
    "const chain = prompt.pipe(model).pipe(parser)\n",
    "\n",
    "const response = await chain.invoke({\n",
    "    country: \"America\",\n",
    "    instructions: parser.getFormatInstructions(),\n",
    "});\n",
    "\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import { z } from \"zod\";\n",
    "import { StructuredOutputParser, OutputFixingParser } from \"langchain/output_parsers\";\n",
    "import { PromptTemplate } from \"@langchain/core/prompts\";\n",
    "import { ChatOpenAI } from \"@langchain/openai\";\n",
    "import { HumanMessage } from \"@langchain/core/messages\";\n",
    "\n",
    "const schema = z.object({\n",
    "  answer:  z.string().describe(\"用户问题的答案\"),\n",
    "  confidence: z.number().min(0).max(100).describe(\"问题答案的可信度评分，满分 100\")\n",
    "});"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const parser = StructuredOutputParser.fromZodSchema(schema);\n",
    "const prompt = PromptTemplate.fromTemplate(\"尽可能的回答用的问题 \\n{instructions} \\n{question}\")\n",
    "//const model = new ChatOpenAI();\n",
    "const model = new ChatOpenAI({\n",
    "    configuration: {\n",
    "        baseURL: \"https://openrouter.ai/api/v1\",\n",
    "    },\n",
    "});\n",
    "\n",
    "const chain = prompt.pipe(model).pipe(parser)\n",
    "const res = await chain.invoke({\n",
    "    question: \"蒙娜丽莎的作者是谁？是什么时候绘制的\",\n",
    "    instructions: parser.getFormatInstructions()\n",
    "})\n",
    "                               \n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const wrongOutput = {\n",
    "  \"answer\": \"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\",\n",
    "  \"sources\": \"90%\" \n",
    "};\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(model, parser);\n",
    "const output = await fixParser.parse(JSON.stringify(wrongOutput));\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const wrongOutput = {\n",
    "  \"answer\": \"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\",\n",
    "  \"sources\": \"-1\" \n",
    "};\n",
    "\n",
    "const fixParser = OutputFixingParser.fromLLM(model, parser);\n",
    "const output = await fixParser.parse(JSON.stringify(wrongOutput));\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(fixParser.getFormatInstructions())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
