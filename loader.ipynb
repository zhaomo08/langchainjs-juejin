{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.599458Z",
     "start_time": "2024-05-26T04:29:02.542344Z"
    }
   },
   "outputs": [],
   "source": [
    "import { Document } from \"langchain/document\";\n",
    "\n",
    "const test = new Document({ pageContent: \"test text\", metadata: { source: \"ABC Title\" } });"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.615741Z",
     "start_time": "2024-05-26T04:29:02.606375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document {\n",
       "  pageContent: \u001b[32m\"test text\"\u001b[39m,\n",
       "  metadata: { source: \u001b[32m\"ABC Title\"\u001b[39m }\n",
       "}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.624083Z",
     "start_time": "2024-05-26T04:29:02.622675Z"
    }
   },
   "outputs": [],
   "source": [
    "import { TextLoader } from \"langchain/document_loaders/fs/text\";\n",
    "const loader = new TextLoader(\"data/qiu.txt\");\n",
    "\n",
    "const docs = await loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.746220Z",
     "start_time": "2024-05-26T04:29:02.630595Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  Document {\n",
      "    pageContent: \"三体前传：球状闪电 作者：刘慈欣\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"内容简介：\\n\" +\n",
      "      \"　　没有《球状闪电》，就没有后来的《三体》！\\n\" +\n",
      "      \"　　《三体》前传！\\n\" +\n",
      "      \"　　亚洲首位雨果奖得主刘慈欣的三大长篇之一！（《三体》《球状闪电》《超新星纪元》）\\n\" +\n",
      "      \"　　《球状闪电》拥有最狂野的想象力！\\n\" +\n",
      "      \"　　带你从另一个维度观察世界！\\n\" +\n",
      "      \"　　全面展现刘慈欣对人生的终极思考！\\n\" +\n",
      "      \"　　《三体》中解决可控核聚变的顶级物理学家丁仪，正是《球状闪电》中找到球状闪电的关键人物。\\n\" +\n",
      "      \"　　《三体》中一号面壁人的幽灵军队计划，正是来自于《球状闪电》。\\n\" +\n",
      "      \"　　《球状闪电》中的疑似宇宙观察者，为《三体》中的智子出现铺陈了线索。\\n\" +\n",
      "      \"　　《球状闪电》和《三体》是刘慈欣两个不同时期的巅峰之作，《球状闪电》是他对人生的终极思考，《三体》则是他对宇宙的终极思考。\\n\" +\n",
      "      \"　　过一个美妙的人生并不难，关键在于你迷上的是什么。\\n\" +\n",
      "      \"　　某个离奇的雨夜，一颗球状闪电在一瞬间将少年的父母化为灰烬，而他们身下的板凳却分毫无损。\\n\" +\n",
      "      \"　　从此少年踏上了研究球状闪电的旅程，死亡者的幽灵笔迹、前苏联的地下科技城、次世代的世界大战……\\n\" +\n",
      "      \"　　球状闪电意外成为了战争中决定祖国存亡的终极武器！\\n\" +\n",
      "      \"　　一个从未有人想像过的未来，在宇宙观察者的注视下，悄然降临在人类面前……\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"说明\\n\" +\n",
      "      \"　　本书中对球状闪电特性和行为的描写均以真实历史记录为依据\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"序曲\\n\" +\n",
      "      \"　　今天是我的生日，直到晚上爸爸妈妈点上了生日蛋糕的蜡烛，我们三个围着十四个小火苗坐下来，我才想起这事。\\n\" +\n",
      "      \"　　这是个雷雨之夜，整个宇宙似乎是由密集的闪电和我们的小屋组成。当那蓝色的电光闪起时，窗外的雨珠在一瞬间看得清清楚楚，那雨珠似乎凝固了，像密密地挂在天地间的一串串晶莹的水晶。这时我的脑海中就有一个闪念：世界要是那样的也很有意思，你每天一出门，就在那水晶的密帘中走路，它们在你周围发出丁零丁零的响声，只是，这样玲珑剔透的世界，如何经得住那暴烈的雷电呢……世界在我的眼中总和在别人眼中不一样，我总是努力使世界变形，这是我长这么大对自己唯一的认识。\\n\" +\n",
      "      \"　　暴雨是从傍晚开始的，自那以后闪电和雷声越来越密，开始，每当一道闪电过后，我脑海中一边回忆着刚才窗外那转瞬即逝的水晶世界，一边绷紧头皮等待着那一声炸雷，但现在，闪电太密集了，我已分不出哪声雷属于哪个闪电了。\\n\" +\n",
      "      \"　　在这狂暴的雷雨之夜最能体会出家的珍贵，想象着外面那恐怖危险的世界，家的温暖怀抱让人陶醉。这时，你会深深同情外面大自然中那些在暴雨和雷电下发抖的没有家的生灵，你想打开窗子让它们飞进来，但你又不敢这么做，外面的世界太可怕，你不敢让一丝外面的恐怖气息进入到家的温暖的空间里来。\\n\" +\n",
      "      \"　　“人生啊，人生这东西……”爸爸一口气喝干了一大杯酒，眼睛直勾勾地看着那一簇小火苗说，“变幻莫测，一切都是概率和机遇，就像在一条小溪中漂着的一根小树枝，让一块小石头绊住了，或让一个小旋涡圈住了……”\\n\" +\n",
      "      \"　　“孩子还小，听不懂这些。”妈妈说。\\n\" +\n",
      "      \"　　“他不小了！”爸爸说，“他已到了可以知道人生真相的时候了！”\\n\" +\n",
      "      \"　　“你自己好像知道似的。”妈妈带着嘲讽的笑说。\\n\" +\n",
      "      \"　　“我知道，当然知道！”爸爸又干了半杯酒，然后转向我，“其实，儿子，过一个美妙的人生并不难，听爸爸教你：你选一个公认的世界难题，最好是只用一张纸和一支铅笔的数学难题，比如哥德巴赫猜想或费尔马大定理什么的，或连纸笔都不要的纯自然哲学难题，比如宇宙的本源之类，投入全部身心钻研，只问耕耘不问收获，不知不觉的专注中，一辈子也就过去了。人们常说的寄托，也就是这么回事。或是相反，把挣钱作为唯一的目标，所有的时间都想着怎么挣，也不用问挣来干什么用，到死的时候像葛朗台一样抱着一堆金币说：啊，真暖和啊……所以，美妙人生的关键在于你能迷上什么东西。比如我——”爸爸指指房间里到处摆放着的那些小幅水彩画，它们的技法都很传统，画得中规中矩，从中看不出什么灵气来。这些画映着窗外的电光，像一群闪动的屏幕，“我迷上了画画，虽然知道自己成不了凡·高。”\\n\" +\n",
      "      \"　　“是啊，理想主义者和玩世不恭的人都觉得对方很可怜，可他们实际都很幸运。”妈妈若有所思地说。\\n\" +\n",
      "      \"　　平时成天忙碌的爸爸妈妈这时都变成了哲学家，倒好像这是他们在过生日。\\n\" +\n",
      "      \"　　“妈，别动！”我说着，从妈妈看上去乌黑浓密的头发中拔出一根白头发，只白了一半，另一半还是黑的。\\n\" +\n",
      "      \"　　爸爸拿着那根头发对着灯看了看，闪电中，它像灯丝似的发出光来。“据我所知，这是你妈妈有生以来长出的第一根白发，至少是第一次发现。”\\n\" +\n",
      "      \"　　“干什么吗你？！拔一根要长七根的！”妈妈把头发甩开，恼怒地说。\\n\" +\n",
      "      \"　　“唉，这就是人生了。”爸爸说，他指着蛋糕上的蜡烛，“想想你拿着这么一根小蜡烛，放到戈壁滩上去点燃它，也许当时没风，真让你点着了，然后你离开，远远地你看着那火苗有什么感觉？孩子，这就是生命和人生，脆弱而飘忽不定，经不起一丝微风。”\\n\" +\n",
      "      \"　　我们三个都默默无语地看着那一簇小火苗，看着它们在从窗外射入的冰冷的青色电光中颤抖，像是看着我们精心培育的一窝小生命。\\n\" +\n",
      "      \"　　窗外又一阵剧烈闪电。\\n\" +\n",
      "      \"　　这时它来了，是穿墙进来的，它从墙上那幅希腊众神狂欢的油画旁出现，仿佛是来自画中的一个幽灵。它有篮球大小，发着朦胧的红光。它在我们的头顶上轻盈地飘动着，身后拖着一条发出暗红色光芒的尾迹，它的飞行路线变幻不定，那尾迹在我们上方划出了一条令人迷惑的复杂曲线。它在飘动时发出一种啸叫，那啸叫低沉中透着尖利，让人想到在太古的荒原上，一个鬼魂在吹着埙。\\n\" +\n",
      "      \"　　妈妈惊恐地用双手抓住爸爸，我恨她这个动作恨了一辈子，如果她没那样做，我以后可能至少还有一个亲人。\\n\" +\n",
      "      \"　　它继续飘着，仿佛在寻找着什么，终于它找到了。它悬停在爸爸头顶上半米处，啸叫声变得低沉，断断续续，仿佛是冷笑。\\n\" +\n",
      "      \"　　这时我可以看到它的内部，那半透明的红色辉光似乎有无限深，从那不见底的光雾的深渊中，不断地有大群蓝色的小星星飞出来，像是太空中一个以超光速飞行的灵魂所看到的星空。\\n\" +\n",
      "      \"　　后来知道，它的内部能量密度高达每立方厘米两万至三万焦耳，而即使是TNT炸药的能量密度也不过每立方厘米两千焦耳。虽然它的内部温度高达一万多度，表面却是冷凉的。\\n\" +\n",
      "      \"　　爸爸向上伸出手，他显然并不是去摸它，而是想护住自己的头部。当他的手伸到最高点时，似乎产生了一种吸力，把它吸到手上，就像一片叶子的细尖吸下了一滴露珠。\\n\" +\n",
      "      \"　　一道炫目的白炽，一声巨响，仿佛世界在身边爆炸。\\n\" +\n",
      "      \"　　当眼睛因强光造成的暗雾散去后，我看到了将伴随我一生的景象：像在图像处理软件的色彩模式中选了黑白一样，爸爸和妈妈的身体瞬间变成了黑白两色的，更确切地说是灰白色，黑色是灯光在皱折处照出的阴影。那是一种大理石的颜色。爸爸的手仍旧向上举着，妈妈仍旧倾身用双手抓着爸爸的另一只手臂，在这两尊雕像的面容上，那两双已石化的眼睛仍旧栩栩如生。\\n\" +\n",
      "      \"　　空气中有一种怪异的气味，后来我知道那是臭氧的气味。\\n\" +\n",
      "      \"　　“爸！”我喊了一声。没有回答。\\n\" +\n",
      "      \"　　“妈！”我又喊了一声。没有回答。\\n\" +\n",
      "      \"　　我向那两尊雕像靠过去，这是我一生中最恐惧的时刻。我以前经历过的恐惧大多在梦中，在噩梦的世界中我之所以没有精神崩溃，是因为我的一个下意识在梦中仍醒着，一个声音在我意识最偏远的角落对我喊：这是梦。我现在也在心里拼命地冲自己这样喊，这是支撑我走过去的唯一动力。我伸出颤抖的手，去触碰爸爸的身体，当我的手接触到他肩部那灰白色的表面时，感觉像是穿透了一层极薄极脆的薄壳。我听到了轻微的噼啪声，像是严冬时倒入开水的玻璃杯的爆裂声，两尊雕像在我眼前坍塌下去，像一场微型的雪崩。\\n\" +\n",
      "      \"　　地毯上出现了两堆白灰，除此之外什么都没有了。\\n\" +\n",
      "      \"　　但他们坐过的木凳还在那里，上面也落了一层灰。我拂去上面的灰，看到它的表面完好无损，而且摸上去是冰凉凉的。我知道，在火葬场的炉子中，要把人体完全化为灰烬，要在两千度的高温下烧三十分钟，所以这是梦。\\n\" +\n",
      "      \"　　我茫然四顾，看到有烟从书架中冒出来，有玻璃门的书架中充满了白烟。我走过去拉开书架的门，白烟散尽，我看到里面的书约有三分之一变成灰烬，颜色同地毯上那两堆灰一样，但书架没有任何烧过的痕迹，这是梦。\\n\" +\n",
      "      \"　　我看到一股蒸汽从半开的冰箱中冒出，走过去拉开冰箱门，发现里面的一只生冻鸡已变成熟的，发出一股香味，还有那些生对虾和生鱼，都熟了，但冰箱完好无损，正发出压缩机启动时的声响，这是梦。\\n\" +\n",
      "      \"　　我身上有些异样的感觉，拉开夹克，一片灰烬从我的身上散落下来，我里面穿的背心被烧成了灰，外面的夹克好好的，我刚才更没感觉到什么。我翻夹克的口袋，手被狠狠烫了一下，拿出来一看，装在里面的掌上机已变成一团熔化塑料。这的确是梦，好奇妙的梦啊！\\n\" +\n",
      "      \"　　我木然地坐回我的位子上，我看不到桌子对面地毯上那两小堆灰，但知道它们在那儿。外面的雷声弱了，闪电少了，后来雨停了，再后来月亮从云缝中探出来，把一抹神秘的银光投进窗。我仍木然地坐在那儿，一动不动，这时在我的意识中世界已不存在，我悬浮在无际的虚空中。不知过了多长时间，窗外的朝阳唤醒了我，我木然地站起身，拿起书包去上学，我要摸索着找书包，摸索着打开门，因为我的两眼一直木然地看着无限远方……\\n\" +\n",
      "      \"　　当一个星期后我的精神基本恢复正常时，记起来的第一件事就是那夜是我的生日之夜，但那个蛋糕上应该只插一根蜡烛，哦不，一根都不插，那是我的新生之夜，以后的我再也不是以前那个我了。\\n\" +\n",
      "      \"　　像爸爸在生命的最后时刻说的那样，我迷上了一样东西，我要去经历他所说的美妙人生了。\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"上篇\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"大学\\n\" +\n",
      "      \"　　主要课程：高等数学、理论力学、流体力学、计算机原理及应用、计算机语言及程序设计、动力气象、天气学原理、中国天气、统计预报、中长期天气预报、数值预报等；\\n\" +\n",
      "      \"　　选修课有：大气环流、天气学诊断分析、暴雨与中尺度天气、雷暴预测及避防、热带天气、气候变化与短期气候预测、雷达气象和卫星气象、空气污染与城市气候、高原天气、大气海洋相互作用等。\\n\" +\n",
      "      \"　　五天前，我处理了家里的所有东西，到这座千里之外的南方城市来上大学。当我最后一次关上已经空荡荡的家门时，知道自己把童年和青春永远留在那里了，以后的我，将是单纯追寻一个目标的机器。\\n\" +\n",
      "      \"　　看着这份将占据我四年大学生活的课程清单，我多少有些失望。里面大多数的东西是我不需要的，而有些我最需要的东西，比如电磁学和等离子体物理之类的课程，又没有。我知道自己可能报错了专业，应该报物理专业而不是大气科学专业。\\n\" +\n",
      "      \"　　以后，我一头扎进了图书馆，把几乎所有的时间都花在数学、电磁学、流体力学和等离子体物理上，只有当有涉及这些内容的课时我才去听，其他的课一般都不去。丰富多彩的大学生活与我无关，我也不感兴趣。我每天夜里都在一两点才回到宿舍，听着某个室友在梦中喃喃地念着女朋友的名字，这才意识到还有另一种生活。\\n\" +\n",
      "      \"　　有一天晚上，十二点已过，我从那本厚厚的《偏微分方程》上抬起头来，以为这间专为夜读的学生开的阅览室中又是只剩我一人了，但看到桌对面坐着一个本班叫戴琳的漂亮女生，她面前没有书，只是用双手撑着脑袋看着我。即使对她的那一大堆追求者来说，这目光也不会让他们陶醉，那是一种在己方阵营中发现间谍的目光，一种看异类的目光，我不知道她已这样看了我多长时间。\\n\" +\n",
      "      \"　　“你这人很特别，看得出来，你不是书呆子，你的目的性很强。”她说。\\n\" +\n",
      "      \"　　“嗯？你们没有目的吗？”我随口问，也许，我是在班上唯一没同她说过话的男生。\\n\" +\n",
      "      \"　　“我们的目的是泛泛的，而你，你肯定在找什么很具体的东西！”\\n\" +\n",
      "      \"　　“你看人很准。”我冷冷地说，同时收拾书站起身。我是唯一不需时时对她表现自己的人，所以有一种优越感。\\n\" +\n",
      "      \"　　“你在找什么？”当我走到门口时，她在后面喊。\\n\" +\n",
      "      \"　　“你不会感兴趣的。”我头也不回地走了。\\n\" +\n",
      "      \"　　在外面宁静的秋夜中，我看着满天繁星，空中似乎传来了爸爸的声音：“美妙人生的关键在于你能迷上什么东西。”我现在真正体会到他这话的正确，我现在的人生好比一颗疾飞的炮弹，除了对到达目标时那一声爆炸的渴望之外什么都没有。这个目标完全是非功利的，达到它就意味着生活的完结，我不知道为什么要去那儿，我只是想去，这就够了，这是人类最本源的冲动。很奇怪的，到现在为止，我一次都没有去查过它的资料。我和它，像两个要用一生时间准备一场决斗的骑士，当我没准备好的时候，既不去见它也不去想它。\\n\" +\n",
      "      \"　　转眼三个学期过去了，这段时间在我的感觉中很连续，并没有被假期打断，无家可归的我所有的假期都在学校里度过。一个人住在空旷的宿舍楼中，我丝毫没有孤独感，只有在除夕之夜，听着外面的鞭炮声，我才多少想到了它出现之前的生活，那生活已恍若隔世。这几夜，在停了暖气的宿舍中，寒冷使我的梦格外生动，我本以为这一夜爸爸妈妈会在梦中出现，但他们没有来。记得有一个印度传说，说一个国王所深爱的王妃死去，国王决定为她建造一座前所未有的豪华陵墓，他为这座陵墓耗尽了大半生的心血，当陵墓完工时，他看到正中放着的王妃的棺木，说：这东西放在这儿多不协调，把它搬走。\\n\" +\n",
      "      \"　　在我的心中，爸爸妈妈已远去了，现在占据了全部位置的是它。\\n\" +\n",
      "      \"　　但接下来的事情，使我自己那本已很简单的世界又复杂起来。\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"异象之一\\n\" +\n",
      "      \"　　大二的暑假，我回了一趟家，是为了把那套旧房子租出去，以解决我以后的学杂费。\\n\" +\n",
      "      \"　　回到家时天已经黑了，我摸索着开了锁推门进去，开灯后看到了那熟悉的一切。那张曾在那个雷雨之夜放过生日蛋糕的桌子仍摆在屋正中，那三把椅子也仍在桌边放着，仿佛我昨天才离开。我在沙发上疲惫地坐下，打量着自己的家，感觉有什么地方不对，这种感觉开始很模糊，后来却越来越明显，好像迷雾的航程中时隐时现的暗礁，让我不得不正视它，终于，我找到了这感觉的源泉：\\n\" +\n",
      "      \"　　仿佛昨天才离开。\\n\" +\n",
      "      \"　　我仔细看看桌面，上面有一层薄薄的灰尘，但相对于我离去的这两年时间，这灰尘确实太薄了些。\\n\" +\n",
      "      \"　　我一脸的汗水和尘土，就走进卫生间去洗脸。打开灯后，看到了镜子中清晰的自己，是的，太清晰了，镜子不应该这么干净的。清楚地记得小学时的一个暑假，我和父母一起外出旅游，只走了一个星期，回来后我就用手指在镜面的灰尘上画出一个小人儿来，现在我又用手指在镜面上画了几下，什么都没画出来。\\n\" +\n",
      "      \"　　我拧开水龙头，关了两年的铁管龙头，流出的应是充满铁锈的浑水，但现在流出的水十分清亮。\\n\" +\n",
      "      \"　　洗完脸回到客厅，我又注意到了另外一件事：两年前我最后离开时，关门前匆匆看了屋里一眼，怕忘了什么，看到桌上放着我的一个玻璃杯，就想回去把杯子倒扣过来以免落进灰尘，但肩上背着行李包，再进门有些费劲，就打消了这个念头，这个细节我记得很清楚。\\n\" +\n",
      "      \"　　但现在，桌上的那个杯子是倒扣着的！\\n\" +\n",
      "      \"　　这时，邻居们看到灯光走了进来，都向我说起对一名上大学的孤儿该说的亲切温暖的话，并许诺为我代办房屋出租的事宜，如果将来毕业后不能回来，还负责为我将这套房卖个好价钱。\\n\" +\n",
      "      \"　　“这里的环境好像比我走时干净了许多。”谈到这两年的变化时，我随口说了一句。\\n\" +\n",
      "      \"　　“干净了？你什么眼神啊！靠酒厂那边的那个火电厂在去年投产发电了，现在的烟尘比你走时多了一倍！嘿，现在还有能变干净的地方？”\\n\" +\n",
      "      \"　　我看看那只有薄薄灰尘的桌面，没说什么，但当他们告辞时，还是忍不住问了一句他们中是否谁有我家的家门钥匙。邻居们惊奇地互相看看，都肯定地说没有，我相信他们，因为家门共有五把钥匙，现在完好的还剩三把，我两年前离开时都带走了，有一把现在我带着，另外两把留在我远方的大学宿舍中。\\n\" +\n",
      "      \"　　邻居们走后我又检查了所有的窗户，都牢牢地关着，没有被破坏的痕迹。\\n\" +\n",
      "      \"　　还有另外两把家门钥匙，是我父母带着的。但是，在那个夜里，它们都被熔化了。我不可能忘记自己是怎样从父母的骨灰堆中找出那两块形状不规则的金属，那是熔化后又凝结的两串钥匙，它们现在也放在我那千里之外的宿舍中，作为对那种不可思议的能量的纪念。\\n\" +\n",
      "      \"　　我坐了一会儿，开始收拾东西，这些东西是在房间出租后准备寄存到别处或带走的。我首先收拾的是父亲的那些水彩画，它们是这个房间里为数不多的我真正想保留的东西。我首先把墙上挂着的那几幅取下来，接着取出放在柜子中的，我尽可能地把所有的画都找出来，把它们一起装进纸箱。最后看到书架的底层还有一幅，由于它画面朝下放着，所以刚才没注意到。把这幅画放进箱子前我瞟了一眼画面，目光立刻被钉死在上面。\\n\" +\n",
      "      \"　　这是一幅风景画，画的是在我家门口看到的景物。这周围的景色平淡乏味，几幢灰暗的四层旧楼房，几排白杨，因落满灰尘而显得没什么生气……作为一名三流业余画家的父亲是很懒的，他很少外出写生，只是乐此不疲地画着周围这些灰蒙蒙的景色，还说什么没有平淡的景色，只有平庸的画家。而他就是一个这样的画家，这些平淡的景色经过他那没有灵气的画笔的临摹，更添了一层呆板，倒真是这灰暗的北方城市日常生活的写照。我现在手里拿着的就是这样一幅画，与箱子里许多张类似的画一样，没什么特别引人之处。\\n\" +\n",
      "      \"　　但我注意到画中有一样东西，那是一座水塔，与周围的旧楼相比它的色彩稍微艳丽了一些，像一朵高大的喇叭花。这本来也没有什么特别之处，外面，那座水塔确实存在，我抬头看看窗外，看到它那高高的塔身在城市的灯光前呈一个漆黑的剪影。\\n\" +\n",
      "      \"　　只是，这座水塔是在我考上大学之后才建成的，我两年前离开时，塔身只在脚手架中建了一半。\\n\" +\n",
      "      \"　　我浑身颤抖了一下，手中的画掉在地上。在这盛夏之夜，似乎有一股寒气充满了这个家。\\n\" +\n",
      "      \"　　我把那幅画塞进纸箱，把箱子严严地盖好，转身去收拾其他东西。我努力把注意力集中在正在干的事上，但我的思想仿佛是一根用细丝悬吊着的铁针，而那个纸箱子是一块强磁铁，我可以努力将针转向其他方向，但只要这种努力一松懈，针立刻又被吸回那个方向。外面下雨了，雨滴打在窗玻璃上发出轻响，我总觉得这响声是从那个箱子中发出的……最后，实在忍受不了，我快步走向纸箱，将它打开来，把那幅画拿出来，小心地将画面朝下拿着它走向卫生间，掏出打火机从一角点燃了它。当画烧到三分之一时，我忍不住又将它翻了过来，画面上的那座水塔更加栩栩如生，仿佛要从画纸上凸现出来。我看着火焰吞没了它，画出它的水彩被烧焦了，火苗呈现一种怪异而妖艳的色彩。我把将要烧尽的画扔进盥洗池，看着它烧完，然后打开水龙头，将灰烬冲走。关上水龙头后，我的目光落到了盥洗池的池沿上，看到了刚才洗脸时没注意的东西。\\n\" +\n",
      "      \"　　几根头发，很长的头发。\\n\" +\n",
      "      \"　　那是几根白发，有的全白，与池面几乎融为一体；有的则白了一半，正是那些黑的部分使我看到了它们。这不可能是我两年前留下的，我从来没有过这么长的头发，更没有白发。我轻轻拿起其中一根半黑半白的长发。\\n\" +\n",
      "      \"　　……拔一根长七根……\\n\" +\n",
      "      \"　　我将头发扔掉，仿佛它烫手似的。那根头发在空气中慢慢飘落，竟拖着一道尾迹，那尾迹是由许多头发自身的转瞬即逝的映像组成，就好像我的视觉暂留时间延长了许多似的。这根头发并没有落回池沿上，它只落了一半的高度就在半空中消失了。我再看池沿上其他头发，它们也都消失得无影无踪了。\\n\" +\n",
      "      \"　　我把脑袋放到水龙头下冲了好长时间，然后木然地回到客厅，坐在沙发上，听着外面的雨声。雨已经下得很大了，是一场暴雨，但没有雷声和闪电。雨打在窗上，听上去像一个人或许多人的低语，仿佛在提醒我什么。听久了，我渐渐想象出了那低语的内容，它一遍遍地重复着，听起来越来越真实：\\n\" +\n",
      "      \"　　“那天有雷，那天有雷，那天有雷，那天有雷，那天有雷……”\\n\" +\n",
      "      \"　　我再次在一个暴雨之夜在家里一直坐到天亮，然后再次木然地离开了家，我知道自己把什么东西永远留在这里，也知道自己永远不会再回来了。\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"\\n\" +\n",
      "      \"球状闪电\\n\" +\n",
      "      \"　　我必须要面对它了，因为开学后，大气电学专业的课程就要开始了。\\n\" +\n",
      "      \"　　讲大气电学的是一名叫张彬的副教授，这人五十岁左右，个子不高不矮，眼镜不薄不厚，讲话声音不高不低，课讲得不好不坏，总之，是那种最一般的人，他唯一与众不同的地方是腿有些瘸，但不注意就看不出来。\\n\" +\n",
      "      \"　　这天下午下课后，阶梯教室中只剩我和张彬两人，他在讲台上收拾东西，没有注意到我。时值深秋，夕阳把几缕金色的光投进来，窗台上落了一层金黄色的落叶，内心一向冷漠的我突然意识到，这是作诗的季节了。\\n\" +\n",
      "      \"　　我站起来走到讲台前，“张老师，我想请教个问题，与今天的课无关。”\\n\" +\n",
      "      \"　　张彬抬头看了我一眼，点了点头，又低头收拾东西。\\n\" +\n",
      "      \"　　“关于球状闪电，您能告诉我些什么？”我说出了那个一直深埋在心中但从未说出口的的词。\\n\" +\n",
      "      \"　　张彬的手停止了动作，抬起头，但没看我，而是看着窗外的夕阳，仿佛那就是我指的东西。“你想知道些什么？”过了几秒钟他才问。\\n\" +\n",
      "      \"　　“关于它的一切。”我说。\\n\" +\n",
      "      \"　　张彬一动不动地直视着夕阳，任阳光直射到脸上，这时阳光仍然很亮，他就不觉得刺眼吗？\\n\" +\n",
      "      \"　　“比如，它的历史记录。”我不得不问得更详细些。\\n\" +\n",
      "      \"　　“在欧洲，它在中世纪就有记载；在中国，比较详细的记载是明代的张居正写下的。但直到1837年才有了第一次正规的科学记载，作为一种自然现象，它在最近四十年才为科学界所接受。”\\n\" +\n",
      "      \"　　“那么，关于它的理论呢？”\\n\" +\n",
      "      \"　　“有很多种。”张彬简单地说了一句后又不吱声了。他把目光从夕阳上收回来，但没有接着收拾东西，像在深思着什么。\\n\" +\n",
      "      \"　　“最传统的理论是什么？”\\n\" +\n",
      "      \"　　“认为它是一种涡旋状高温等离子体，由于内部高速旋转造成的离心力与外部大气压力达到平衡，因而维持了较长时间的稳定性。”\\n\" +\n",
      "      \"　　“还有吗？”\\n\" +\n",
      "      \"　　“还有人认为它是高温混合气体之间的化学反应，从而维持了能量的稳定。”\\n\" +\n",
      "      \"　　“您能告诉我更多一些吗？”我说。向他提问，如同费力地推着一个沉重的石碾子，推一下才动一下。\\n\" +\n",
      "      \"　　“还有微波激射—孤立子理论，认为球状闪电是由体积约为若干立方米的大气微波激射所引起的。微波激射相当于能量低得多的激光，在空气体积很大时，微波激射会产生局部电场即孤立子，从而导致看得见的球状闪电。”\\n\" +\n",
      "      \"　　“那么最新的理论呢？”\\n\" +\n",
      "      \"　　“也有很多，比较受到注意的是新西兰坎特伯雷大学的亚伯拉罕森和迪尼斯的理论，认为球状闪电主要是由微型含硅颗粒组成的网络球体燃烧形成。其他的五花八门，甚至有人认为它是空气中的常温核聚变。”\\n\" +\n",
      "      \"　　张彬停了一下，终于说出了更多的内容：“在国内，中科院大气所有人提出了大气中等离子体的理论，从电磁流体力学方程出发，引入旋涡—孤立子谐振腔模型，在适当温度场边界条件下，通过数值求解方程，从理论上得到了大气中等离子体涡团—火球的解以及它存在的必要和充分条件。”\\n\" +\n",
      "      \"　　“您认为这些理论怎么样？”\\n\" +\n",
      "      \"　　张彬缓缓地摇了摇头，“要证明这些理论的正确，只有在实验室中产生出球状闪电，但至今没人能成功。”\\n\" +\n",
      "      \"　　“在国内，目击球状闪电的案例有多少？”\\n\" +\n",
      "      \"　　“不少，有上千份吧。其中最著名的是1998年中央电视台拍摄的长江抗洪纪录片中，无意间清晰地摄下了一个球状闪电。”\\n\" +\n",
      "      \"　　“张老师，最后一个问题：在国内大气物理学界，有亲眼看见过它的人吗？”\\n\" +\n",
      "      \"　　张彬又抬头看窗外的夕阳：“有。”\\n\" +\n",
      "      \"　　“什么时间？”\\n\" +\n",
      "      \"　　“1962年7月。”\\n\" +\n",
      "      \"　　“什么地方？”\\n\" +\n",
      "      \"　　“泰山玉皇顶。”\\n\" +\n",
      "      \"　　“您知道这人现在在哪儿吗？”\\n\" +\n",
      "      \"　　张彬摇了摇头，抬腕看了看表，“你该去食堂打饭了。”说完拿起他的东西径自朝外走去。\\n\" +\n",
      "      \"　　我追上了他，把这么多年来自己心中的问题全部倾泻出来，“张老师，您能够想象有这么一种东西，以一团火球的形式毫不困难地穿过墙壁，在空气中飞行时你感觉不到它的一点热量，却能瞬间把人烧成灰？有记载它曾把睡在被窝里的一对夫妻烧成灰，被子上却连一道焦痕都没留下！您能想象它进入冰箱，瞬间使里面的所有冷冻食品都变成冒热气的熟食，而冰箱本身还在不受任何影响地运转？您能想象它把您的贴身衬衣烧焦，而您竟没有感觉？您说的那些理论能解释这一切吗？”\\n\" +\n",
      "      \"　　“我说过那些理论都不成立。”张彬说，他没有停步。\\n\" +\n",
      "      \"　　“那么，我们越出大气物理学的范围，您认为现今的整个物理学，甚至整个科学能解释这现象吗？您就丝毫不感到好奇？看到您这样，我真比见到球状闪电还吃惊！”\\n\" +\n",
      "      \"　　张彬停下了脚步，转过身来第一次正视我，“你见过球状闪电？”\\n\" +\n",
      "      \"　　“……我只是比喻。”\\n\" +\n",
      "      \"　　我无法把内心最深处的秘密告诉眼前这个麻木的人，这种对大自然那深邃神秘的麻木充斥着整个社会，对科学来说早就是一种公害。如果这种人在学术界少一些，人类现在说不定已飞抵人马座了！\\n\" +\n",
      "      \"　　张彬说：“大气物理学是一门很实用的科学，球状闪电是一种极其罕见的现象，在国际建筑物防雷标准IEC/TC-81，以及我国1993年颁布的《建筑物防雷设计规范》中，都没有考虑到它，所以，在这东西上花太多的精力，意义不大。”\\n\" +\n",
      "      \"　　和这种人真没什么太多的话好讲，我谢过他转身走人。要知道，他能承认球状闪电的存在，已经是一大进步了！直到1963年，科学界才正式认同这种闪电的存在，这之前，所有的目击报告都被断定为幻觉。这一年的一天，美国肯特大学\"... 179496 more characters,\n",
      "    metadata: { source: \"data/qiu.txt\" }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "console.log(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.756379Z",
     "start_time": "2024-05-26T04:29:02.753159Z"
    }
   },
   "outputs": [],
   "source": [
    "import * as pdfParse from \"pdf-parse\";\n",
    "import { PDFLoader } from \"langchain/document_loaders/fs/pdf\";\n",
    "\n",
    "const loader = new PDFLoader(\"data/github-copliot.pdf\");\n",
    "const pdfs = await loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.815921Z",
     "start_time": "2024-05-26T04:29:02.763339Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot1/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常\\n\"\u001b[39m +\n",
       "      \u001b[32m\"工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Nov 25, 2023\\n\"\u001b[39m +\n",
       "      \u001b[32m\"LLMchinese\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“原文来自于 x 推文，所以保留了原始分段的⻛格”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"0. 一些基础信息\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. github copilot 是 gpt3 针对代码场景优化而来的 Codex 模型，其基础性能不如\\n\"\u001b[39m +\n",
       "      \u001b[32m\"gpt4，但在代码场景效果更好\\n\"\u001b[39m +\n",
       "      \u001b[32m\" Kai\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m1\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot2/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 不是银弹，并不是一秒解决 50% 的工作，而是将 50% 的工作时间替换\\n\"\u001b[39m +\n",
       "      \u001b[32m\"成了 10% 的 prompt/chat 时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 认清 copilot 的定位，其是一个副驾驶的⻆色，自己的思维方式要从“如何去做这\\n\"\u001b[39m +\n",
       "      \u001b[32m\"件事” => “如何激发 copilot 去做这件事”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 尝试 ai-native 的开发方式，从自己编码 + ai copilot 到自己编写 prompt、\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 编码，然后自己去进行修改\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 已经非常强，但还是一个发布并不久的工具，深度使用需要思考如何更贴\\n\"\u001b[39m +\n",
       "      \u001b[32m\"近它的思维和使用方式，也会遇到很多 bug\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 再强调一下，copilot 不是银弹，不是你告诉他需求他就能够输出完美方案的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"bot，你只是把编码时间换成了 更少 prompt 时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 不要编程这件事妄自菲薄，不要高看也不要低看，一个学习过所有开源代码的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 编程能力是很强的。但依旧需要人类去“激活”和引导，且人类也有其独特的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"优势\\n\"\u001b[39m +\n",
       "      \u001b[32m\"1. 基本使用思路\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 把自己的视野拉高，让 copilot 去做更低维度的事情\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 是极度廉价劳动力，是可以让他去帮你试错、可以多开浪费他的思考来节\\n\"\u001b[39m +\n",
       "      \u001b[32m\"约自己的思考时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 问 copilot 的问题，自己需要至少有鉴别基础质量的能力，从而能够对他的输出\\n\"\u001b[39m +\n",
       "      \u001b[32m\"取其精华。在不擅⻓的领域完全信赖会导致非常严重的问题\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 不要懒得写⻓的 prompt，从 llm 的原理来说，你给的 context 越多，他越容易召\\n\"\u001b[39m +\n",
       "      \u001b[32m\"回到你想要的知识，并给你需要的答案，把他看作一个知识丰富的人类助手，用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"给人类讲话的耐心去写 prompt。你会发现这事并不会花你太多时间\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m2\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot3/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2.变量命名\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这是非常基础但是很多人浪费了很多时间的点。你可以把你想要的这个 变量/类 想要\\n\"\u001b[39m +\n",
       "      \u001b[32m\"承担的任务和一些想法给到 copilot chat，然他输出你需要的命名\\n\"\u001b[39m +\n",
       "      \u001b[32m\"并且，copilot 的劳动力极度廉价，灵活应用 “给我十个，再给我十个，再给我十个”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"人类想出十个合适答案的能力不如 llm，但很擅⻓从十个答案中选出合适的一个\\n\"\u001b[39m +\n",
       "      \u001b[32m\"3. 代码速读，代码精读，加注释解析，寻找修改项\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m3\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot4/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"接收其他人项目、读开源项目等情况，找到需要读的文件，全选，然后打开 copilot\\n\"\u001b[39m +\n",
       "      \u001b[32m\"chat（它会读取你选中的代码），使用内置的 /explian 命令，这个会内置一些 prompt\\n\"\u001b[39m +\n",
       "      \u001b[32m\"让输出质量更好\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我常用的几句话是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“从架构设计⻆度，分析这段代码的设计思路，并讲解这种思路的优劣”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“分析 xxx 函数的详细逻辑，以及在整个文件中起到的作用”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“给 xxx 函数每一行加上注释，以详细解析该函数”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我现在需要通过修改这个文件以实现 xxx 功能，如何修改？”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我现在需要用 ts 重写这段 python 代码，详细解析这段 python 代码的设计逻辑，并\\n\"\u001b[39m +\n",
       "      \u001b[32m\"分析如何在 ts 中实现”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解析这段代码中可能有哪些⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“在这段代码中， run 和 test 方法有什么区别”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"所以在我修一个大系统的 bug 时，我会对多个可能的文件问类似于 “我的需求是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"xxx，能通过修改这个文件实现么？”，直到找到我需要修改的地方和方案。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 读懂代码逻辑的速度极快，可以快速给你一个 80 分的答案，你再判断是否有必要\\n\"\u001b[39m +\n",
       "      \u001b[32m\"精读。然后再使用 copilot 辅助精读。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"4. 代码改写，用 xx 库实现整体逻辑\\n\"\u001b[39m +\n",
       "      \u001b[32m\"在要用 b 库改写使用 a 库实现的逻辑时，copilot 做的非常快，因为你 a 库写的逻辑\\n\"\u001b[39m +\n",
       "      \u001b[32m\"就是最完美的 prompt，在实现完往往只需要通读一边确认答案即可。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这里涉及到对 context 的应用，而因为 codex 的数据库更新并不及时，可能并不了解\\n\"\u001b[39m +\n",
       "      \u001b[32m\"b 库。 那一个常用的小技巧：\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是 b 库这个函数的文档，帮我改写这部分用 a 库写的逻辑”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是 b 库的官方实例，我想用 b 实现 xx 功能，帮我实现”\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m4\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot5/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这种 few shot 的 prompt 技巧，可以极大程度提高输出质量。不只是在这种场景，很\\n\"\u001b[39m +\n",
       "      \u001b[32m\"多场景可以应用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"5. ai-native 的开发方式\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 依旧是个初期产品，但随着发展一定会越来越强大。所以我们应该尝试使用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"ai-native 的开发模式，学着更深入的使用 copilot.\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我常用的技巧\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我需要一个 ts 类，他的使用方式和调用方式是：<伪代码>，帮我实现一个最基础的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"版本”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个其实替代了之前 模板插件 的功能，帮你更快的搭起一个 class 的基础框架，然\\n\"\u001b[39m +\n",
       "      \u001b[32m\"后自己填充细节。 （不会只有我每次都忘记一些 class 的语法还需要每次搜索文档\\n\"\u001b[39m +\n",
       "      \u001b[32m\"）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"全选所有类代码，然后 “我给这个类添加一个 xxx 函数，帮我参考现有代码，进行实\\n\"\u001b[39m +\n",
       "      \u001b[32m\"现”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"往往质量够用，甚至可以直接使用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“在这个 class 内，我想记录一个逐步产生的 xxx 数据，应该用什么结构比较符合 ts\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的编程模式，帮我设计解释你的思路”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是我设计的 class/架构/数据结构，目的是 xxx，从优点和缺点各提五点理由，并详\\n\"\u001b[39m +\n",
       "      \u001b[32m\"细解释原因”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"大模型的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"所以先让 copilot 替你思考，很多时候他给的架构非常优秀。即使给的质量比较差，\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一个错误的答案对你的思考也是有益的。 更何况廉价的劳动力，你可以引导他生成非\\n\"\u001b[39m +\n",
       "      \u001b[32m\"常多，也可以质疑他的架构，并提出你看到的问题，多次沟通直到生成有意义的架构\\n\"\u001b[39m +\n",
       "      \u001b[32m\"或者理清楚自己的思路。\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m5\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot6/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"ai-native 不是让 ai 设计架构，而是与 ai 多次讨论，让自己的思路更加清晰。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"有时候我们知道这个架构有点问题，但不知道怎么改，ai 会给你思路。有时候我们不\\n\"\u001b[39m +\n",
       "      \u001b[32m\"知道这个架构有什么问题，ai 可以帮你找到问题。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"总是，大模型的劳动力极度廉价，用他大量的思考来节约自己的思考\\n\"\u001b[39m +\n",
       "      \u001b[32m\"6. 报错解析\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这是我高强度使用的一个点，首先代码报错信息是给人类读的，但又不是人类可读的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"，且人类很难有 llm 那样无限的上下文和知识\\n\"\u001b[39m +\n",
       "      \u001b[32m\"除了非常基础的报错信息，先复制给 copilot chat，使用内置的 /explain 命令，让他\\n\"\u001b[39m +\n",
       "      \u001b[32m\"分析报错。如果是 vsc 用户，现在已经有一键操作了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"再强调一遍，llm 不是银弹，他的答案有偏差，一定注意引导。并且，你问的问题一\\n\"\u001b[39m +\n",
       "      \u001b[32m\"定是你能够判断基础对错的问题。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"常用的几句话\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解释这个报错，并分析可能的原因和修改方式”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我认为这不是报错的根源，根据你的知识，给出三种可能的出错根源”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"尝试一次，你就会发现，与其自己花时间去思考和分析报错，不让先让 llm 给你一个\\n\"\u001b[39m +\n",
       "      \u001b[32m\"80 分的答案，在大多数时间他的答案已经可以帮你解决问题了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"7. 解释 review message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"无论是作为一个 junior sde 还是一个开源新人，外加人类语言表达的局限性。 很多\\n\"\u001b[39m +\n",
       "      \u001b[32m\"review message 并没有那么明确，与其自己想半天，不如先让 llm 分析下。\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m6\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot7/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"复制对应的 diff 和你认为合适的上下文，附加上 review message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是我的前辈对我的 pr 的 comments，帮我分析意思，并提出合适的解决方案”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 的知识库对此做出的解析，以及对 review 黑话/缩写 的分析，往往结果还不错\\n\"\u001b[39m +\n",
       "      \u001b[32m\"8. 提高代码质量，设计优化\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 读过的代码太多了，常用的几句话\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这个 class 的设计有没有考虑到 xxx 的问题”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解析这个 class 是否有安全⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“...， 在哪些场景场景在可能会有泄露⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这个 class 如何针对 xxx 做优化”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"注意，一般直接问可能并不能拿到高质量的回答，需要人类做方向性的引导，比如提\\n\"\u001b[39m +\n",
       "      \u001b[32m\"示在什么问题、什么方面等 prompt，可以帮助 llm 沿着具体思路思考\\n\"\u001b[39m +\n",
       "      \u001b[32m\"并且要灵活使用 “给我 5 个 xx，并详细解释原因”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"9. 灵活使用 cmd+i\\n\"\u001b[39m +\n",
       "      \u001b[32m\"最新的 copilot 支持了直接在代码上唤起 chat，你可以选中一段代码，然后 cmd +\\n\"\u001b[39m +\n",
       "      \u001b[32m\"i，输出你的 prompt，比如 “使用 promise.all 改写” “添加类型注释”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个很多人没注意到这个功能，结合前面提到的 prompt 技巧很好用。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"但目前 diff 功能有些 bug，在部分时候会删改不需要的代码，注意灵活应对。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我一般是把需要代码复制出来，然后 ctrl z 掉他所有更改，然后再粘贴进去。\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m7\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot8/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"因为这个功能没有上下文，但也有多次对话的能力。适合比较小的需求点，大的最好\\n\"\u001b[39m +\n",
       "      \u001b[32m\"是用 copliot chat\\n\"\u001b[39m +\n",
       "      \u001b[32m\"10. 写 commit message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个已经在最新的 vsc 中集成，根据你本次的 diff 生成 commit message。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个思路非常好，但实测其⻛格不太符合我日常的⻛格，我相信这个未来会有⻛格选\\n\"\u001b[39m +\n",
       "      \u001b[32m\"型，或者以你之前的 commit message 作为上下文进行生成。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"目前我推荐在这个 generate 的基础上自己修改，或通过 chat 的方式生成\\n\"\u001b[39m +\n",
       "      \u001b[32m\"11. 基础脚手架、基础 poc\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这也是 ai-native 的一部分，也是我最近用起来比较顺手的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我要写一个 nodejs 库，帮我写 一个基础的 rollup 配置、tsconfig 和 package.json\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的配置” “帮我用 react 写一个基础的 xxx 组件”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"前者是，很多时候没有好用的现成配置，用 llm 就很方便。后者是有一个迅速能看到\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的基础代码，会帮助你思考和工作。\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m8\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot9/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"12. 中间插入一些唠叨\\n\"\u001b[39m +\n",
       "      \u001b[32m\"vsc 设置成你最熟悉的自然语言！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"虽然未来（或者已经）会有给 copilot chat 单独设置自然语言的功能，但我建议直接\\n\"\u001b[39m +\n",
       "      \u001b[32m\"把 vsc 设置成你最熟悉的自然语言。然后方便的速读\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 不是人类，不用字斟句酌，有合适的关键词即可。如果不知道怎么表达，就用最\\n\"\u001b[39m +\n",
       "      \u001b[32m\"暴力的表达方式即可\\n\"\u001b[39m +\n",
       "      \u001b[32m\"写 prompt 的时间 和 写 code 的时间，这两个随着深入使用，你会逐步找到自己舒服\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的状态。当你做一个事情的时候，你会知道是使用 llm 还是直接写 code 会更快/质量\\n\"\u001b[39m +\n",
       "      \u001b[32m\"更高。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一般理想的是 人类冷启动/llm 冷启动 => 人类编写细节/llm 编写细节 => 人类 polish /\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm polish\\n\"\u001b[39m +\n",
       "      \u001b[32m\"熟练后，在每个阶段都可以非常快速的判断出，这个时候是人类做还是 llm 做，还是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一起做\\n\"\u001b[39m +\n",
       "      \u001b[32m\"13. llm as doc/search\\n\"\u001b[39m +\n",
       "      \u001b[32m\"再强调，一定要问 llm 自己能够判断基础对错的问题！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这里的工具就不限于的 copilot chat 了，我一般也会混着 new bing （有联网能力）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"使用。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"比如\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“ts 中，interface 和 type 的区别”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“ts decorators 是否 stable？现在进入 stage 几了？”（new bing）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"几个非常好用的 magic word：“举例详细说明”、“详细对比这两个的优缺点”、“举出\\n\"\u001b[39m +\n",
       "      \u001b[32m\"实际场景对比这两个区别”、“使用 xxx 函数，写一个简单 demo，介绍其优势”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"作完调研后，“用 xx 实现我的 xx 需求”，从调研到实现，几分钟 几轮对话，就结束了\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m9\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot10/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一定要有基础的技术视野和知识去判断其输出的质量。我遇到过好几次，llm 硬着脖\\n\"\u001b[39m +\n",
       "      \u001b[32m\"子非要用 moment 去处理 ts 中的时间，直接被我喷回去，然后乖乖用 dayjs 了 \\n\"\u001b[39m +\n",
       "      \u001b[32m\"14. 碎碎念\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我因为开源项目，一直可以免费用 copilot，算是非常老的用户了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"之前比较流行的写注释然后让 copilot 补全代码的模式一直不太会用，会让我觉得很\\n\"\u001b[39m +\n",
       "      \u001b[32m\"怪。但 copilot chat 确实是 game changer，几天内就替代了我 50% 的工作。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我相信下一次⻜跃就是 copilot 带联网功能的时候，到时候会进一步挤压人类的编码\\n\"\u001b[39m +\n",
       "      \u001b[32m\"空间，亦或是说，人类可以更从容的做更有创造性的工作。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"顺嘴提一句 copilot labs，可能很多人都不知道有这个东⻄。 在 chat 出来之前玩玩还\\n\"\u001b[39m +\n",
       "      \u001b[32m\"可以，在 chat 面前一文不值的 \"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m10\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot11/14\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m11\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot12/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"15. vsc plugin 开发\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这也是我看很多人没提到的点，我日常工作有 vsc plugin 的开发工作，copilot chat\\n\"\u001b[39m +\n",
       "      \u001b[32m\"已经内置了 plugin 相关的文档，你可以直接用自然语言提问你的问题和需要开发的功\\n\"\u001b[39m +\n",
       "      \u001b[32m\"能在 vsc 中如何实现。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"也可以通过 /help 命令，看看 chat 内置的一些功能，这些功能往往伴随着内置的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"prompt 和数据库，对特定任务有增强\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m12\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot13/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"© 2024 Kai\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m13\u001b[39m }\n",
       "    }\n",
       "  },\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot14/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"鲁ICP备2022030649号\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      },\n",
       "      loc: { pageNumber: \u001b[33m14\u001b[39m }\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.823453Z",
     "start_time": "2024-05-26T04:29:02.822891Z"
    }
   },
   "outputs": [],
   "source": [
    "const loader = new PDFLoader(\"data/github-copliot.pdf\", { splitPages: false });\n",
    "const pdf = await loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.830739Z",
     "start_time": "2024-05-26T04:29:02.830357Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\n",
       "  Document {\n",
       "    pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot1/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常\\n\"\u001b[39m +\n",
       "      \u001b[32m\"工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"Nov 25, 2023\\n\"\u001b[39m +\n",
       "      \u001b[32m\"LLMchinese\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“原文来自于 x 推文，所以保留了原始分段的⻛格”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"0. 一些基础信息\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. github copilot 是 gpt3 针对代码场景优化而来的 Codex 模型，其基础性能不如\\n\"\u001b[39m +\n",
       "      \u001b[32m\"gpt4，但在代码场景效果更好\\n\"\u001b[39m +\n",
       "      \u001b[32m\" Kai\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot2/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 不是银弹，并不是一秒解决 50% 的工作，而是将 50% 的工作时间替换\\n\"\u001b[39m +\n",
       "      \u001b[32m\"成了 10% 的 prompt/chat 时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 认清 copilot 的定位，其是一个副驾驶的⻆色，自己的思维方式要从“如何去做这\\n\"\u001b[39m +\n",
       "      \u001b[32m\"件事” => “如何激发 copilot 去做这件事”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 尝试 ai-native 的开发方式，从自己编码 + ai copilot 到自己编写 prompt、\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 编码，然后自己去进行修改\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 已经非常强，但还是一个发布并不久的工具，深度使用需要思考如何更贴\\n\"\u001b[39m +\n",
       "      \u001b[32m\"近它的思维和使用方式，也会遇到很多 bug\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 再强调一下，copilot 不是银弹，不是你告诉他需求他就能够输出完美方案的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"bot，你只是把编码时间换成了 更少 prompt 时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 不要编程这件事妄自菲薄，不要高看也不要低看，一个学习过所有开源代码的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 编程能力是很强的。但依旧需要人类去“激活”和引导，且人类也有其独特的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"优势\\n\"\u001b[39m +\n",
       "      \u001b[32m\"1. 基本使用思路\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 把自己的视野拉高，让 copilot 去做更低维度的事情\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. copilot 是极度廉价劳动力，是可以让他去帮你试错、可以多开浪费他的思考来节\\n\"\u001b[39m +\n",
       "      \u001b[32m\"约自己的思考时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 问 copilot 的问题，自己需要至少有鉴别基础质量的能力，从而能够对他的输出\\n\"\u001b[39m +\n",
       "      \u001b[32m\"取其精华。在不擅⻓的领域完全信赖会导致非常严重的问题\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\x00. 不要懒得写⻓的 prompt，从 llm 的原理来说，你给的 context 越多，他越容易召\\n\"\u001b[39m +\n",
       "      \u001b[32m\"回到你想要的知识，并给你需要的答案，把他看作一个知识丰富的人类助手，用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"给人类讲话的耐心去写 prompt。你会发现这事并不会花你太多时间\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot3/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2.变量命名\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这是非常基础但是很多人浪费了很多时间的点。你可以把你想要的这个 变量/类 想要\\n\"\u001b[39m +\n",
       "      \u001b[32m\"承担的任务和一些想法给到 copilot chat，然他输出你需要的命名\\n\"\u001b[39m +\n",
       "      \u001b[32m\"并且，copilot 的劳动力极度廉价，灵活应用 “给我十个，再给我十个，再给我十个”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"人类想出十个合适答案的能力不如 llm，但很擅⻓从十个答案中选出合适的一个\\n\"\u001b[39m +\n",
       "      \u001b[32m\"3. 代码速读，代码精读，加注释解析，寻找修改项\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot4/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"接收其他人项目、读开源项目等情况，找到需要读的文件，全选，然后打开 copilot\\n\"\u001b[39m +\n",
       "      \u001b[32m\"chat（它会读取你选中的代码），使用内置的 /explian 命令，这个会内置一些 prompt\\n\"\u001b[39m +\n",
       "      \u001b[32m\"让输出质量更好\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我常用的几句话是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“从架构设计⻆度，分析这段代码的设计思路，并讲解这种思路的优劣”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“分析 xxx 函数的详细逻辑，以及在整个文件中起到的作用”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“给 xxx 函数每一行加上注释，以详细解析该函数”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我现在需要通过修改这个文件以实现 xxx 功能，如何修改？”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我现在需要用 ts 重写这段 python 代码，详细解析这段 python 代码的设计逻辑，并\\n\"\u001b[39m +\n",
       "      \u001b[32m\"分析如何在 ts 中实现”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解析这段代码中可能有哪些⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“在这段代码中， run 和 test 方法有什么区别”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"所以在我修一个大系统的 bug 时，我会对多个可能的文件问类似于 “我的需求是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"xxx，能通过修改这个文件实现么？”，直到找到我需要修改的地方和方案。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 读懂代码逻辑的速度极快，可以快速给你一个 80 分的答案，你再判断是否有必要\\n\"\u001b[39m +\n",
       "      \u001b[32m\"精读。然后再使用 copilot 辅助精读。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"4. 代码改写，用 xx 库实现整体逻辑\\n\"\u001b[39m +\n",
       "      \u001b[32m\"在要用 b 库改写使用 a 库实现的逻辑时，copilot 做的非常快，因为你 a 库写的逻辑\\n\"\u001b[39m +\n",
       "      \u001b[32m\"就是最完美的 prompt，在实现完往往只需要通读一边确认答案即可。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这里涉及到对 context 的应用，而因为 codex 的数据库更新并不及时，可能并不了解\\n\"\u001b[39m +\n",
       "      \u001b[32m\"b 库。 那一个常用的小技巧：\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是 b 库这个函数的文档，帮我改写这部分用 a 库写的逻辑”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是 b 库的官方实例，我想用 b 实现 xx 功能，帮我实现”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot5/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这种 few shot 的 prompt 技巧，可以极大程度提高输出质量。不只是在这种场景，很\\n\"\u001b[39m +\n",
       "      \u001b[32m\"多场景可以应用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"5. ai-native 的开发方式\\n\"\u001b[39m +\n",
       "      \u001b[32m\"copilot 依旧是个初期产品，但随着发展一定会越来越强大。所以我们应该尝试使用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"ai-native 的开发模式，学着更深入的使用 copilot.\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我常用的技巧\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我需要一个 ts 类，他的使用方式和调用方式是：<伪代码>，帮我实现一个最基础的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"版本”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个其实替代了之前 模板插件 的功能，帮你更快的搭起一个 class 的基础框架，然\\n\"\u001b[39m +\n",
       "      \u001b[32m\"后自己填充细节。 （不会只有我每次都忘记一些 class 的语法还需要每次搜索文档\\n\"\u001b[39m +\n",
       "      \u001b[32m\"）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"全选所有类代码，然后 “我给这个类添加一个 xxx 函数，帮我参考现有代码，进行实\\n\"\u001b[39m +\n",
       "      \u001b[32m\"现”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"往往质量够用，甚至可以直接使用\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“在这个 class 内，我想记录一个逐步产生的 xxx 数据，应该用什么结构比较符合 ts\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的编程模式，帮我设计解释你的思路”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是我设计的 class/架构/数据结构，目的是 xxx，从优点和缺点各提五点理由，并详\\n\"\u001b[39m +\n",
       "      \u001b[32m\"细解释原因”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"大模型的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"所以先让 copilot 替你思考，很多时候他给的架构非常优秀。即使给的质量比较差，\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一个错误的答案对你的思考也是有益的。 更何况廉价的劳动力，你可以引导他生成非\\n\"\u001b[39m +\n",
       "      \u001b[32m\"常多，也可以质疑他的架构，并提出你看到的问题，多次沟通直到生成有意义的架构\\n\"\u001b[39m +\n",
       "      \u001b[32m\"或者理清楚自己的思路。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot6/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"ai-native 不是让 ai 设计架构，而是与 ai 多次讨论，让自己的思路更加清晰。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"有时候我们知道这个架构有点问题，但不知道怎么改，ai 会给你思路。有时候我们不\\n\"\u001b[39m +\n",
       "      \u001b[32m\"知道这个架构有什么问题，ai 可以帮你找到问题。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"总是，大模型的劳动力极度廉价，用他大量的思考来节约自己的思考\\n\"\u001b[39m +\n",
       "      \u001b[32m\"6. 报错解析\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这是我高强度使用的一个点，首先代码报错信息是给人类读的，但又不是人类可读的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"，且人类很难有 llm 那样无限的上下文和知识\\n\"\u001b[39m +\n",
       "      \u001b[32m\"除了非常基础的报错信息，先复制给 copilot chat，使用内置的 /explain 命令，让他\\n\"\u001b[39m +\n",
       "      \u001b[32m\"分析报错。如果是 vsc 用户，现在已经有一键操作了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"再强调一遍，llm 不是银弹，他的答案有偏差，一定注意引导。并且，你问的问题一\\n\"\u001b[39m +\n",
       "      \u001b[32m\"定是你能够判断基础对错的问题。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"常用的几句话\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解释这个报错，并分析可能的原因和修改方式”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我认为这不是报错的根源，根据你的知识，给出三种可能的出错根源”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"尝试一次，你就会发现，与其自己花时间去思考和分析报错，不让先让 llm 给你一个\\n\"\u001b[39m +\n",
       "      \u001b[32m\"80 分的答案，在大多数时间他的答案已经可以帮你解决问题了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"7. 解释 review message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"无论是作为一个 junior sde 还是一个开源新人，外加人类语言表达的局限性。 很多\\n\"\u001b[39m +\n",
       "      \u001b[32m\"review message 并没有那么明确，与其自己想半天，不如先让 llm 分析下。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot7/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"复制对应的 diff 和你认为合适的上下文，附加上 review message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这是我的前辈对我的 pr 的 comments，帮我分析意思，并提出合适的解决方案”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 的知识库对此做出的解析，以及对 review 黑话/缩写 的分析，往往结果还不错\\n\"\u001b[39m +\n",
       "      \u001b[32m\"8. 提高代码质量，设计优化\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 读过的代码太多了，常用的几句话\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这个 class 的设计有没有考虑到 xxx 的问题”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“解析这个 class 是否有安全⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“...， 在哪些场景场景在可能会有泄露⻛险”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“这个 class 如何针对 xxx 做优化”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"注意，一般直接问可能并不能拿到高质量的回答，需要人类做方向性的引导，比如提\\n\"\u001b[39m +\n",
       "      \u001b[32m\"示在什么问题、什么方面等 prompt，可以帮助 llm 沿着具体思路思考\\n\"\u001b[39m +\n",
       "      \u001b[32m\"并且要灵活使用 “给我 5 个 xx，并详细解释原因”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"9. 灵活使用 cmd+i\\n\"\u001b[39m +\n",
       "      \u001b[32m\"最新的 copilot 支持了直接在代码上唤起 chat，你可以选中一段代码，然后 cmd +\\n\"\u001b[39m +\n",
       "      \u001b[32m\"i，输出你的 prompt，比如 “使用 promise.all 改写” “添加类型注释”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个很多人没注意到这个功能，结合前面提到的 prompt 技巧很好用。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"但目前 diff 功能有些 bug，在部分时候会删改不需要的代码，注意灵活应对。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我一般是把需要代码复制出来，然后 ctrl z 掉他所有更改，然后再粘贴进去。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot8/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"因为这个功能没有上下文，但也有多次对话的能力。适合比较小的需求点，大的最好\\n\"\u001b[39m +\n",
       "      \u001b[32m\"是用 copliot chat\\n\"\u001b[39m +\n",
       "      \u001b[32m\"10. 写 commit message\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个已经在最新的 vsc 中集成，根据你本次的 diff 生成 commit message。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这个思路非常好，但实测其⻛格不太符合我日常的⻛格，我相信这个未来会有⻛格选\\n\"\u001b[39m +\n",
       "      \u001b[32m\"型，或者以你之前的 commit message 作为上下文进行生成。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"目前我推荐在这个 generate 的基础上自己修改，或通过 chat 的方式生成\\n\"\u001b[39m +\n",
       "      \u001b[32m\"11. 基础脚手架、基础 poc\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这也是 ai-native 的一部分，也是我最近用起来比较顺手的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“我要写一个 nodejs 库，帮我写 一个基础的 rollup 配置、tsconfig 和 package.json\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的配置” “帮我用 react 写一个基础的 xxx 组件”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"前者是，很多时候没有好用的现成配置，用 llm 就很方便。后者是有一个迅速能看到\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的基础代码，会帮助你思考和工作。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot9/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"12. 中间插入一些唠叨\\n\"\u001b[39m +\n",
       "      \u001b[32m\"vsc 设置成你最熟悉的自然语言！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"虽然未来（或者已经）会有给 copilot chat 单独设置自然语言的功能，但我建议直接\\n\"\u001b[39m +\n",
       "      \u001b[32m\"把 vsc 设置成你最熟悉的自然语言。然后方便的速读\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm 不是人类，不用字斟句酌，有合适的关键词即可。如果不知道怎么表达，就用最\\n\"\u001b[39m +\n",
       "      \u001b[32m\"暴力的表达方式即可\\n\"\u001b[39m +\n",
       "      \u001b[32m\"写 prompt 的时间 和 写 code 的时间，这两个随着深入使用，你会逐步找到自己舒服\\n\"\u001b[39m +\n",
       "      \u001b[32m\"的状态。当你做一个事情的时候，你会知道是使用 llm 还是直接写 code 会更快/质量\\n\"\u001b[39m +\n",
       "      \u001b[32m\"更高。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一般理想的是 人类冷启动/llm 冷启动 => 人类编写细节/llm 编写细节 => 人类 polish /\\n\"\u001b[39m +\n",
       "      \u001b[32m\"llm polish\\n\"\u001b[39m +\n",
       "      \u001b[32m\"熟练后，在每个阶段都可以非常快速的判断出，这个时候是人类做还是 llm 做，还是\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一起做\\n\"\u001b[39m +\n",
       "      \u001b[32m\"13. llm as doc/search\\n\"\u001b[39m +\n",
       "      \u001b[32m\"再强调，一定要问 llm 自己能够判断基础对错的问题！\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这里的工具就不限于的 copilot chat 了，我一般也会混着 new bing （有联网能力）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"使用。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"比如\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“ts 中，interface 和 type 的区别”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"“ts decorators 是否 stable？现在进入 stage 几了？”（new bing）\\n\"\u001b[39m +\n",
       "      \u001b[32m\"几个非常好用的 magic word：“举例详细说明”、“详细对比这两个的优缺点”、“举出\\n\"\u001b[39m +\n",
       "      \u001b[32m\"实际场景对比这两个区别”、“使用 xxx 函数，写一个简单 demo，介绍其优势”\\n\"\u001b[39m +\n",
       "      \u001b[32m\"作完调研后，“用 xx 实现我的 xx 需求”，从调研到实现，几分钟 几轮对话，就结束了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot10/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"一定要有基础的技术视野和知识去判断其输出的质量。我遇到过好几次，llm 硬着脖\\n\"\u001b[39m +\n",
       "      \u001b[32m\"子非要用 moment 去处理 ts 中的时间，直接被我喷回去，然后乖乖用 dayjs 了 \\n\"\u001b[39m +\n",
       "      \u001b[32m\"14. 碎碎念\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我因为开源项目，一直可以免费用 copilot，算是非常老的用户了\\n\"\u001b[39m +\n",
       "      \u001b[32m\"之前比较流行的写注释然后让 copilot 补全代码的模式一直不太会用，会让我觉得很\\n\"\u001b[39m +\n",
       "      \u001b[32m\"怪。但 copilot chat 确实是 game changer，几天内就替代了我 50% 的工作。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"我相信下一次⻜跃就是 copilot 带联网功能的时候，到时候会进一步挤压人类的编码\\n\"\u001b[39m +\n",
       "      \u001b[32m\"空间，亦或是说，人类可以更从容的做更有创造性的工作。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"顺嘴提一句 copilot labs，可能很多人都不知道有这个东⻄。 在 chat 出来之前玩玩还\\n\"\u001b[39m +\n",
       "      \u001b[32m\"可以，在 chat 面前一文不值的 \\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot11/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot12/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"15. vsc plugin 开发\\n\"\u001b[39m +\n",
       "      \u001b[32m\"这也是我看很多人没提到的点，我日常工作有 vsc plugin 的开发工作，copilot chat\\n\"\u001b[39m +\n",
       "      \u001b[32m\"已经内置了 plugin 相关的文档，你可以直接用自然语言提问你的问题和需要开发的功\\n\"\u001b[39m +\n",
       "      \u001b[32m\"能在 vsc 中如何实现。\\n\"\u001b[39m +\n",
       "      \u001b[32m\"也可以通过 /help 命令，看看 chat 内置的一些功能，这些功能往往伴随着内置的\\n\"\u001b[39m +\n",
       "      \u001b[32m\"prompt 和数据库，对特定任务有增强\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot13/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"© 2024 Kai\\n\"\u001b[39m +\n",
       "      \u001b[32m\"\\n\"\u001b[39m +\n",
       "      \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "      \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "      \u001b[32m\"https://kaiyi.cool/blog/github-copilot14/14\\n\"\u001b[39m +\n",
       "      \u001b[32m\"鲁ICP备2022030649号\"\u001b[39m,\n",
       "    metadata: {\n",
       "      source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "      pdf: {\n",
       "        version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "        info: {\n",
       "          PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "          IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "          IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "          Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "          Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "          Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "          CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "          ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "        },\n",
       "        metadata: \u001b[1mnull\u001b[22m,\n",
       "        totalPages: \u001b[33m14\u001b[39m\n",
       "      }\n",
       "    }\n",
       "  }\n",
       "]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.842294Z",
     "start_time": "2024-05-26T04:29:02.837561Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document {\n",
       "  pageContent: \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot1/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常\\n\"\u001b[39m +\n",
       "    \u001b[32m\"工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"Nov 25, 2023\\n\"\u001b[39m +\n",
       "    \u001b[32m\"LLMchinese\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“原文来自于 x 推文，所以保留了原始分段的⻛格”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"0. 一些基础信息\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. github copilot 是 gpt3 针对代码场景优化而来的 Codex 模型，其基础性能不如\\n\"\u001b[39m +\n",
       "    \u001b[32m\"gpt4，但在代码场景效果更好\\n\"\u001b[39m +\n",
       "    \u001b[32m\" Kai\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot2/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. copilot 不是银弹，并不是一秒解决 50% 的工作，而是将 50% 的工作时间替换\\n\"\u001b[39m +\n",
       "    \u001b[32m\"成了 10% 的 prompt/chat 时间\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 认清 copilot 的定位，其是一个副驾驶的⻆色，自己的思维方式要从“如何去做这\\n\"\u001b[39m +\n",
       "    \u001b[32m\"件事” => “如何激发 copilot 去做这件事”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 尝试 ai-native 的开发方式，从自己编码 + ai copilot 到自己编写 prompt、\\n\"\u001b[39m +\n",
       "    \u001b[32m\"copilot 编码，然后自己去进行修改\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. copilot 已经非常强，但还是一个发布并不久的工具，深度使用需要思考如何更贴\\n\"\u001b[39m +\n",
       "    \u001b[32m\"近它的思维和使用方式，也会遇到很多 bug\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 再强调一下，copilot 不是银弹，不是你告诉他需求他就能够输出完美方案的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"bot，你只是把编码时间换成了 更少 prompt 时间\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 不要编程这件事妄自菲薄，不要高看也不要低看，一个学习过所有开源代码的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm 编程能力是很强的。但依旧需要人类去“激活”和引导，且人类也有其独特的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"优势\\n\"\u001b[39m +\n",
       "    \u001b[32m\"1. 基本使用思路\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 把自己的视野拉高，让 copilot 去做更低维度的事情\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. copilot 是极度廉价劳动力，是可以让他去帮你试错、可以多开浪费他的思考来节\\n\"\u001b[39m +\n",
       "    \u001b[32m\"约自己的思考时间\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 问 copilot 的问题，自己需要至少有鉴别基础质量的能力，从而能够对他的输出\\n\"\u001b[39m +\n",
       "    \u001b[32m\"取其精华。在不擅⻓的领域完全信赖会导致非常严重的问题\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\x00. 不要懒得写⻓的 prompt，从 llm 的原理来说，你给的 context 越多，他越容易召\\n\"\u001b[39m +\n",
       "    \u001b[32m\"回到你想要的知识，并给你需要的答案，把他看作一个知识丰富的人类助手，用\\n\"\u001b[39m +\n",
       "    \u001b[32m\"给人类讲话的耐心去写 prompt。你会发现这事并不会花你太多时间\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot3/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2.变量命名\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这是非常基础但是很多人浪费了很多时间的点。你可以把你想要的这个 变量/类 想要\\n\"\u001b[39m +\n",
       "    \u001b[32m\"承担的任务和一些想法给到 copilot chat，然他输出你需要的命名\\n\"\u001b[39m +\n",
       "    \u001b[32m\"并且，copilot 的劳动力极度廉价，灵活应用 “给我十个，再给我十个，再给我十个”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"人类想出十个合适答案的能力不如 llm，但很擅⻓从十个答案中选出合适的一个\\n\"\u001b[39m +\n",
       "    \u001b[32m\"3. 代码速读，代码精读，加注释解析，寻找修改项\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot4/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"接收其他人项目、读开源项目等情况，找到需要读的文件，全选，然后打开 copilot\\n\"\u001b[39m +\n",
       "    \u001b[32m\"chat（它会读取你选中的代码），使用内置的 /explian 命令，这个会内置一些 prompt\\n\"\u001b[39m +\n",
       "    \u001b[32m\"让输出质量更好\\n\"\u001b[39m +\n",
       "    \u001b[32m\"我常用的几句话是\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“从架构设计⻆度，分析这段代码的设计思路，并讲解这种思路的优劣”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“分析 xxx 函数的详细逻辑，以及在整个文件中起到的作用”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“给 xxx 函数每一行加上注释，以详细解析该函数”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“我现在需要通过修改这个文件以实现 xxx 功能，如何修改？”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“我现在需要用 ts 重写这段 python 代码，详细解析这段 python 代码的设计逻辑，并\\n\"\u001b[39m +\n",
       "    \u001b[32m\"分析如何在 ts 中实现”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“解析这段代码中可能有哪些⻛险”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“在这段代码中， run 和 test 方法有什么区别”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"copilot 的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "    \u001b[32m\"所以在我修一个大系统的 bug 时，我会对多个可能的文件问类似于 “我的需求是\\n\"\u001b[39m +\n",
       "    \u001b[32m\"xxx，能通过修改这个文件实现么？”，直到找到我需要修改的地方和方案。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm 读懂代码逻辑的速度极快，可以快速给你一个 80 分的答案，你再判断是否有必要\\n\"\u001b[39m +\n",
       "    \u001b[32m\"精读。然后再使用 copilot 辅助精读。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"4. 代码改写，用 xx 库实现整体逻辑\\n\"\u001b[39m +\n",
       "    \u001b[32m\"在要用 b 库改写使用 a 库实现的逻辑时，copilot 做的非常快，因为你 a 库写的逻辑\\n\"\u001b[39m +\n",
       "    \u001b[32m\"就是最完美的 prompt，在实现完往往只需要通读一边确认答案即可。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这里涉及到对 context 的应用，而因为 codex 的数据库更新并不及时，可能并不了解\\n\"\u001b[39m +\n",
       "    \u001b[32m\"b 库。 那一个常用的小技巧：\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这是 b 库这个函数的文档，帮我改写这部分用 a 库写的逻辑”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这是 b 库的官方实例，我想用 b 实现 xx 功能，帮我实现”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot5/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这种 few shot 的 prompt 技巧，可以极大程度提高输出质量。不只是在这种场景，很\\n\"\u001b[39m +\n",
       "    \u001b[32m\"多场景可以应用\\n\"\u001b[39m +\n",
       "    \u001b[32m\"5. ai-native 的开发方式\\n\"\u001b[39m +\n",
       "    \u001b[32m\"copilot 依旧是个初期产品，但随着发展一定会越来越强大。所以我们应该尝试使用\\n\"\u001b[39m +\n",
       "    \u001b[32m\"ai-native 的开发模式，学着更深入的使用 copilot.\\n\"\u001b[39m +\n",
       "    \u001b[32m\"我常用的技巧\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“我需要一个 ts 类，他的使用方式和调用方式是：<伪代码>，帮我实现一个最基础的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"版本”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这个其实替代了之前 模板插件 的功能，帮你更快的搭起一个 class 的基础框架，然\\n\"\u001b[39m +\n",
       "    \u001b[32m\"后自己填充细节。 （不会只有我每次都忘记一些 class 的语法还需要每次搜索文档\\n\"\u001b[39m +\n",
       "    \u001b[32m\"）\\n\"\u001b[39m +\n",
       "    \u001b[32m\"全选所有类代码，然后 “我给这个类添加一个 xxx 函数，帮我参考现有代码，进行实\\n\"\u001b[39m +\n",
       "    \u001b[32m\"现”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"往往质量够用，甚至可以直接使用\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“在这个 class 内，我想记录一个逐步产生的 xxx 数据，应该用什么结构比较符合 ts\\n\"\u001b[39m +\n",
       "    \u001b[32m\"的编程模式，帮我设计解释你的思路”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这是我设计的 class/架构/数据结构，目的是 xxx，从优点和缺点各提五点理由，并详\\n\"\u001b[39m +\n",
       "    \u001b[32m\"细解释原因”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"大模型的劳动力极度廉价！\\n\"\u001b[39m +\n",
       "    \u001b[32m\"所以先让 copilot 替你思考，很多时候他给的架构非常优秀。即使给的质量比较差，\\n\"\u001b[39m +\n",
       "    \u001b[32m\"一个错误的答案对你的思考也是有益的。 更何况廉价的劳动力，你可以引导他生成非\\n\"\u001b[39m +\n",
       "    \u001b[32m\"常多，也可以质疑他的架构，并提出你看到的问题，多次沟通直到生成有意义的架构\\n\"\u001b[39m +\n",
       "    \u001b[32m\"或者理清楚自己的思路。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot6/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"ai-native 不是让 ai 设计架构，而是与 ai 多次讨论，让自己的思路更加清晰。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"有时候我们知道这个架构有点问题，但不知道怎么改，ai 会给你思路。有时候我们不\\n\"\u001b[39m +\n",
       "    \u001b[32m\"知道这个架构有什么问题，ai 可以帮你找到问题。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"总是，大模型的劳动力极度廉价，用他大量的思考来节约自己的思考\\n\"\u001b[39m +\n",
       "    \u001b[32m\"6. 报错解析\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这是我高强度使用的一个点，首先代码报错信息是给人类读的，但又不是人类可读的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"，且人类很难有 llm 那样无限的上下文和知识\\n\"\u001b[39m +\n",
       "    \u001b[32m\"除了非常基础的报错信息，先复制给 copilot chat，使用内置的 /explain 命令，让他\\n\"\u001b[39m +\n",
       "    \u001b[32m\"分析报错。如果是 vsc 用户，现在已经有一键操作了\\n\"\u001b[39m +\n",
       "    \u001b[32m\"再强调一遍，llm 不是银弹，他的答案有偏差，一定注意引导。并且，你问的问题一\\n\"\u001b[39m +\n",
       "    \u001b[32m\"定是你能够判断基础对错的问题。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"常用的几句话\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“解释这个报错，并分析可能的原因和修改方式”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“我认为这不是报错的根源，根据你的知识，给出三种可能的出错根源”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"尝试一次，你就会发现，与其自己花时间去思考和分析报错，不让先让 llm 给你一个\\n\"\u001b[39m +\n",
       "    \u001b[32m\"80 分的答案，在大多数时间他的答案已经可以帮你解决问题了\\n\"\u001b[39m +\n",
       "    \u001b[32m\"7. 解释 review message\\n\"\u001b[39m +\n",
       "    \u001b[32m\"无论是作为一个 junior sde 还是一个开源新人，外加人类语言表达的局限性。 很多\\n\"\u001b[39m +\n",
       "    \u001b[32m\"review message 并没有那么明确，与其自己想半天，不如先让 llm 分析下。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot7/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"复制对应的 diff 和你认为合适的上下文，附加上 review message\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这是我的前辈对我的 pr 的 comments，帮我分析意思，并提出合适的解决方案”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm 的知识库对此做出的解析，以及对 review 黑话/缩写 的分析，往往结果还不错\\n\"\u001b[39m +\n",
       "    \u001b[32m\"8. 提高代码质量，设计优化\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm 读过的代码太多了，常用的几句话\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这个 class 的设计有没有考虑到 xxx 的问题”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“解析这个 class 是否有安全⻛险”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“...， 在哪些场景场景在可能会有泄露⻛险”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“这个 class 如何针对 xxx 做优化”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"注意，一般直接问可能并不能拿到高质量的回答，需要人类做方向性的引导，比如提\\n\"\u001b[39m +\n",
       "    \u001b[32m\"示在什么问题、什么方面等 prompt，可以帮助 llm 沿着具体思路思考\\n\"\u001b[39m +\n",
       "    \u001b[32m\"并且要灵活使用 “给我 5 个 xx，并详细解释原因”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"9. 灵活使用 cmd+i\\n\"\u001b[39m +\n",
       "    \u001b[32m\"最新的 copilot 支持了直接在代码上唤起 chat，你可以选中一段代码，然后 cmd +\\n\"\u001b[39m +\n",
       "    \u001b[32m\"i，输出你的 prompt，比如 “使用 promise.all 改写” “添加类型注释”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这个很多人没注意到这个功能，结合前面提到的 prompt 技巧很好用。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"但目前 diff 功能有些 bug，在部分时候会删改不需要的代码，注意灵活应对。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"我一般是把需要代码复制出来，然后 ctrl z 掉他所有更改，然后再粘贴进去。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot8/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"因为这个功能没有上下文，但也有多次对话的能力。适合比较小的需求点，大的最好\\n\"\u001b[39m +\n",
       "    \u001b[32m\"是用 copliot chat\\n\"\u001b[39m +\n",
       "    \u001b[32m\"10. 写 commit message\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这个已经在最新的 vsc 中集成，根据你本次的 diff 生成 commit message。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这个思路非常好，但实测其⻛格不太符合我日常的⻛格，我相信这个未来会有⻛格选\\n\"\u001b[39m +\n",
       "    \u001b[32m\"型，或者以你之前的 commit message 作为上下文进行生成。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"目前我推荐在这个 generate 的基础上自己修改，或通过 chat 的方式生成\\n\"\u001b[39m +\n",
       "    \u001b[32m\"11. 基础脚手架、基础 poc\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这也是 ai-native 的一部分，也是我最近用起来比较顺手的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“我要写一个 nodejs 库，帮我写 一个基础的 rollup 配置、tsconfig 和 package.json\\n\"\u001b[39m +\n",
       "    \u001b[32m\"的配置” “帮我用 react 写一个基础的 xxx 组件”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"前者是，很多时候没有好用的现成配置，用 llm 就很方便。后者是有一个迅速能看到\\n\"\u001b[39m +\n",
       "    \u001b[32m\"的基础代码，会帮助你思考和工作。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot9/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"12. 中间插入一些唠叨\\n\"\u001b[39m +\n",
       "    \u001b[32m\"vsc 设置成你最熟悉的自然语言！\\n\"\u001b[39m +\n",
       "    \u001b[32m\"虽然未来（或者已经）会有给 copilot chat 单独设置自然语言的功能，但我建议直接\\n\"\u001b[39m +\n",
       "    \u001b[32m\"把 vsc 设置成你最熟悉的自然语言。然后方便的速读\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm 不是人类，不用字斟句酌，有合适的关键词即可。如果不知道怎么表达，就用最\\n\"\u001b[39m +\n",
       "    \u001b[32m\"暴力的表达方式即可\\n\"\u001b[39m +\n",
       "    \u001b[32m\"写 prompt 的时间 和 写 code 的时间，这两个随着深入使用，你会逐步找到自己舒服\\n\"\u001b[39m +\n",
       "    \u001b[32m\"的状态。当你做一个事情的时候，你会知道是使用 llm 还是直接写 code 会更快/质量\\n\"\u001b[39m +\n",
       "    \u001b[32m\"更高。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"一般理想的是 人类冷启动/llm 冷启动 => 人类编写细节/llm 编写细节 => 人类 polish /\\n\"\u001b[39m +\n",
       "    \u001b[32m\"llm polish\\n\"\u001b[39m +\n",
       "    \u001b[32m\"熟练后，在每个阶段都可以非常快速的判断出，这个时候是人类做还是 llm 做，还是\\n\"\u001b[39m +\n",
       "    \u001b[32m\"一起做\\n\"\u001b[39m +\n",
       "    \u001b[32m\"13. llm as doc/search\\n\"\u001b[39m +\n",
       "    \u001b[32m\"再强调，一定要问 llm 自己能够判断基础对错的问题！\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这里的工具就不限于的 copilot chat 了，我一般也会混着 new bing （有联网能力）\\n\"\u001b[39m +\n",
       "    \u001b[32m\"使用。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"比如\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“ts 中，interface 和 type 的区别”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"“ts decorators 是否 stable？现在进入 stage 几了？”（new bing）\\n\"\u001b[39m +\n",
       "    \u001b[32m\"几个非常好用的 magic word：“举例详细说明”、“详细对比这两个的优缺点”、“举出\\n\"\u001b[39m +\n",
       "    \u001b[32m\"实际场景对比这两个区别”、“使用 xxx 函数，写一个简单 demo，介绍其优势”\\n\"\u001b[39m +\n",
       "    \u001b[32m\"作完调研后，“用 xx 实现我的 xx 需求”，从调研到实现，几分钟 几轮对话，就结束了\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot10/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"一定要有基础的技术视野和知识去判断其输出的质量。我遇到过好几次，llm 硬着脖\\n\"\u001b[39m +\n",
       "    \u001b[32m\"子非要用 moment 去处理 ts 中的时间，直接被我喷回去，然后乖乖用 dayjs 了 \\n\"\u001b[39m +\n",
       "    \u001b[32m\"14. 碎碎念\\n\"\u001b[39m +\n",
       "    \u001b[32m\"我因为开源项目，一直可以免费用 copilot，算是非常老的用户了\\n\"\u001b[39m +\n",
       "    \u001b[32m\"之前比较流行的写注释然后让 copilot 补全代码的模式一直不太会用，会让我觉得很\\n\"\u001b[39m +\n",
       "    \u001b[32m\"怪。但 copilot chat 确实是 game changer，几天内就替代了我 50% 的工作。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"我相信下一次⻜跃就是 copilot 带联网功能的时候，到时候会进一步挤压人类的编码\\n\"\u001b[39m +\n",
       "    \u001b[32m\"空间，亦或是说，人类可以更从容的做更有创造性的工作。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"顺嘴提一句 copilot labs，可能很多人都不知道有这个东⻄。 在 chat 出来之前玩玩还\\n\"\u001b[39m +\n",
       "    \u001b[32m\"可以，在 chat 面前一文不值的 \\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot11/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot12/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"15. vsc plugin 开发\\n\"\u001b[39m +\n",
       "    \u001b[32m\"这也是我看很多人没提到的点，我日常工作有 vsc plugin 的开发工作，copilot chat\\n\"\u001b[39m +\n",
       "    \u001b[32m\"已经内置了 plugin 相关的文档，你可以直接用自然语言提问你的问题和需要开发的功\\n\"\u001b[39m +\n",
       "    \u001b[32m\"能在 vsc 中如何实现。\\n\"\u001b[39m +\n",
       "    \u001b[32m\"也可以通过 /help 命令，看看 chat 内置的一些功能，这些功能往往伴随着内置的\\n\"\u001b[39m +\n",
       "    \u001b[32m\"prompt 和数据库，对特定任务有增强\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot13/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"© 2024 Kai\\n\"\u001b[39m +\n",
       "    \u001b[32m\"\\n\"\u001b[39m +\n",
       "    \u001b[32m\"2024/3/24 20:59\\n\"\u001b[39m +\n",
       "    \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\\n\"\u001b[39m +\n",
       "    \u001b[32m\"https://kaiyi.cool/blog/github-copilot14/14\\n\"\u001b[39m +\n",
       "    \u001b[32m\"鲁ICP备2022030649号\"\u001b[39m,\n",
       "  metadata: {\n",
       "    source: \u001b[32m\"data/github-copliot.pdf\"\u001b[39m,\n",
       "    pdf: {\n",
       "      version: \u001b[32m\"1.10.100\"\u001b[39m,\n",
       "      info: {\n",
       "        PDFFormatVersion: \u001b[32m\"1.4\"\u001b[39m,\n",
       "        IsAcroFormPresent: \u001b[33mfalse\u001b[39m,\n",
       "        IsXFAPresent: \u001b[33mfalse\u001b[39m,\n",
       "        Title: \u001b[32m\"如何使用 github copilot 完成 50% 的日常工作\"\u001b[39m,\n",
       "        Creator: \u001b[32m\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/123.0.0.0 Safari/537.36\"\u001b[39m,\n",
       "        Producer: \u001b[32m\"Skia/PDF m123\"\u001b[39m,\n",
       "        CreationDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m,\n",
       "        ModDate: \u001b[32m\"D:20240324125917+00'00'\"\u001b[39m\n",
       "      },\n",
       "      metadata: \u001b[1mnull\u001b[22m,\n",
       "      totalPages: \u001b[33m14\u001b[39m\n",
       "    }\n",
       "  }\n",
       "}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:02.885121Z",
     "start_time": "2024-05-26T04:29:02.849223Z"
    }
   },
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:08.874336Z",
     "start_time": "2024-05-26T04:29:02.891991Z"
    }
   },
   "outputs": [],
   "source": [
    "import { GithubRepoLoader } from \"langchain/document_loaders/web/github\";\n",
    "import ignore from \"ignore\";\n",
    "\n",
    "const loader = new GithubRepoLoader(\n",
    "    \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
    "    { \n",
    "        branch: \"main\",\n",
    "        recursive: false, \n",
    "        unknown: \"warn\", \n",
    "        ignorePaths: [\"*.md\", \"yarn.lock\", \"*.json\"],\n",
    "        accessToken: env[\"GITHUB_TOKEN\"]\n",
    "    }\n",
    "  );"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:08.884846Z",
     "start_time": "2024-05-26T04:29:08.881421Z"
    }
   },
   "outputs": [],
   "source": [
    "const docs = await loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:08.892770Z",
     "start_time": "2024-05-26T04:29:08.891958Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  Document {\n",
      "    pageContent: \"#AZURE_OPENAI_API_KEY=abc\\n\" +\n",
      "      \"#AZURE_OPENAI_API_VERSION=2023-07-01-preview\\n\" +\n",
      "      \"#AZURE_OPENAI_API_DEPLOYMENT_NAME=abc\\n\" +\n",
      "      \"#AZURE_OPENAI_API_INSTANCE_NAME=abc\\n\" +\n",
      "      \"#AZURE_OPENAI_API_EMBEDDINGS_DEPLOYMENT_NAME=abc\\n\" +\n",
      "      \"#GITHUB_TOKEN=abc\\n\" +\n",
      "      \"#SERP_KEY=abc\\n\" +\n",
      "      \"#\\n\" +\n",
      "      \"#SMI_KEY=abc\\n\" +\n",
      "      \"#TAVILY_KEY=abc\",\n",
      "    metadata: {\n",
      "      source: \".env.example\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \".ipynb_checkpoints\\n.env\\nnode_modules\",\n",
      "    metadata: {\n",
      "      source: \".gitignore\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"4e51ba54-3bfd-4384-b476-e793544191d0\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"a8216718-c062-4755-a749-c9b80ff8467c\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { z } from \\\\\"zod\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { JsonOutputToolsParser } from \\\\\"@langchain/core/output_parsers/openai_tools\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RunnableSequence, RunnableBranch, RunnablePassthrough } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { zodToJsonSchema } from \\\\\"zod-to-json-schema\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatPromptTemplate, PromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \" \\\\n\",\\n' +\n",
      "      '    \"const classifySchema = z.object({\\\\n\",\\n' +\n",
      "      '    \"    type: z.enum([\\\\\"科普\\\\\", \\\\\"编程\\\\\", \\\\\"一般问题\\\\\"]).describe(\\\\\"用户提问的分类\\\\\")\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0 \\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const modelWithTools = model.bind({\\\\n\",\\n' +\n",
      "      '    \"    tools: [\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"classifyQuestion\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"对用户的提问进行分类\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(classifySchema),\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    ],\\\\n\",\\n' +\n",
      "      '    \"    tool_choice: {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"           name: \\\\\"classifyQuestion\\\\\"\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", `仔细思考，你有充足的时间进行严谨的思考，然后对用户的问题进行分类，\\\\n\",\\n' +\n",
      "      '    \"    当你无法分类到特定分类时，可以分类到 \\\\\"一般问题\\\\\"`],\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"human\\\\\", \\\\\"{input}\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const classifyChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    prompt,\\\\n\",\\n' +\n",
      "      '    \"    modelWithTools,\\\\n\",\\n' +\n",
      "      '    \"    new JsonOutputToolsParser(),\\\\n\",\\n' +\n",
      "      '    \"    (input) => {\\\\n\",\\n' +\n",
      "      '    \"        const type = input[0]?.args?.type\\\\n\",\\n' +\n",
      "      '    \"        return type ? type : \\\\\"一般问题\\\\\"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"4dd65030-e4a8-4dae-b859-42c54251012e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await classifyChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"input\\\\\": \\\\\"鲸鱼是哺乳动物么？\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"b3817a63-926c-4d2c-bc15-b630d372668d\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const answeringModel = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0.7,\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const sciencePrompt = PromptTemplate.fromTemplate(\\\\n\",\\n' +\n",
      "      '    \"  `作为一位科普专家，你需要解答以下问题，尽可能提供详细、准确和易于理解的答案：\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"问题：{input}\\\\n\",\\n' +\n",
      "      '    \"答案：`\\\\n\",\\n' +\n",
      "      '    \")\\\\n\",\\n' +\n",
      "      '    \"    \\\\n\",\\n' +\n",
      "      '    \"const programmingPrompt = PromptTemplate.fromTemplate(\\\\n\",\\n' +\n",
      "      '    \"  `作为一位编程专家，你需要解答以下编程相关的问题，尽可能提供详细、准确和实用的答案：\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"问题：{input}\\\\n\",\\n' +\n",
      "      '    \"答案：`\\\\n\",\\n' +\n",
      "      '    \")\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const generalPrompt = PromptTemplate.fromTemplate(\\\\n\",\\n' +\n",
      "      '    \"  `请回答以下一般性问题，尽可能提供全面和有深度的答案：\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"问题：{input}\\\\n\",\\n' +\n",
      "      '    \"答案：`\\\\n\",\\n' +\n",
      "      '    \")\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const scienceChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    sciencePrompt,\\\\n\",\\n' +\n",
      "      '    \"    answeringModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        output: input => input,\\\\n\",\\n' +\n",
      "      '    \"        role: () => \\\\\"科普专家\\\\\"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"    \\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const programmingChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    programmingPrompt,\\\\n\",\\n' +\n",
      "      '    \"    answeringModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        output: input => input,\\\\n\",\\n' +\n",
      "      '    \"        role: () => \\\\\"编程大师\\\\\"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"    \\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const generalChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    generalPrompt,\\\\n\",\\n' +\n",
      "      '    \"    answeringModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        output: input => input,\\\\n\",\\n' +\n",
      "      '    \"        role: () => \\\\\"通识专家\\\\\"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"    \\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"6e76cf62-cbdf-4a72-aa0f-9173b7e81aa5\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const branch = RunnableBranch.from([\\\\n\",\\n' +\n",
      "      '    \"  [\\\\n\",\\n' +\n",
      "      '    \"    (input => input.type.includes(\\\\\"科普\\\\\")),\\\\n\",\\n' +\n",
      "      '    \"    scienceChain,\\\\n\",\\n' +\n",
      "      '    \"  ],\\\\n\",\\n' +\n",
      "      '    \"  [\\\\n\",\\n' +\n",
      "      '    \"    (input => input.type.includes(\\\\\"编程\\\\\")),\\\\n\",\\n' +\n",
      "      '    \"    programmingChain,\\\\n\",\\n' +\n",
      "      '    \"  ],\\\\n\",\\n' +\n",
      "      '    \"  generalChain\\\\n\",\\n' +\n",
      "      '    \"]);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"da1fe98b-8887-452e-8007-a2aa78992e98\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const outputTemplate = PromptTemplate.fromTemplate(\\\\n\",\\n' +\n",
      "      '    \"`感谢您的提问，这是来自 {role} 的专业回答：\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"{output}\\\\n\",\\n' +\n",
      "      '    \"`)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const finalChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        type: classifyChain,\\\\n\",\\n' +\n",
      "      '    \"        input: input => input.input\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    branch,\\\\n\",\\n' +\n",
      "      '    \"    (input) => outputTemplate.format(input),\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"543fb03e-c1ad-404a-a5a8-36ed84d726be\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await finalChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"input\\\\\": \\\\\"鲸鱼是哺乳动物么？\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(res)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"57dafeab-a265-4db2-8111-0691486cf6da\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const route = ({ type }) => {\\\\n\",\\n' +\n",
      "      '    \"    if(type.includes(\\\\\"科普\\\\\")){\\\\n\",\\n' +\n",
      "      '    \"        return scienceChain\\\\n\",\\n' +\n",
      "      '    \"    }else if(type.includes(\\\\\"编程\\\\\")){\\\\n\",\\n' +\n",
      "      '    \"        return programmingChain\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"    return generalChain\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"bb9a09a0-9d4a-4a1c-a259-15d4cabd9492\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const finalChain2 = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        type: classifyChain,\\\\n\",\\n' +\n",
      "      '    \"        input: input => input.input\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    route,\\\\n\",\\n' +\n",
      "      '    \"    (input) => outputTemplate.format(input),\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"ffd3d7ee-85c1-4ae8-8e59-88d214e2e8ed\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await finalChain2.invoke({\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"input\\\\\": \\\\\"鲸鱼是哺乳动物么？\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 5\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"agent.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await model.invoke([\\\\n\",\\n' +\n",
      "      '    \"    new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"//const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const outputPrase = new StringOutputParser();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const simpleChain = chatModel.pipe(outputPrase)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await simpleChain.invoke([\\\\n\",\\n' +\n",
      "      '    \"    new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await simpleChain.batch([\\\\n\",\\n' +\n",
      "      '    \"    [ new HumanMessage(\\\\\"Tell me a joke\\\\\") ],\\\\n\",\\n' +\n",
      "      '    \"    [ new HumanMessage(\\\\\"Hi, Who are you?\\\\\") ],\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const stream = await simpleChain.stream([\\\\n\",\\n' +\n",
      "      '    \"     new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"for await (const chunk of stream){\\\\n\",\\n' +\n",
      "      '    \"    console.log(chunk)\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const stream = await simpleChain.streamLog([\\\\n\",\\n' +\n",
      "      '    \"     new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"for await (const chunk of stream){\\\\n\",\\n' +\n",
      "      '    \"    console.log(chunk)\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:49:46.573859Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:49:43.836440Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"//const fakeLLM = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"//    azureOpenAIApiKey: \\\\\"123\\\\\",\\\\n\",\\n' +\n",
      "      '    \"//    maxRetries: 0,\\\\n\",\\n' +\n",
      "      '    \"//});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"//await fakeLLM.invoke(\\\\\"你好\\\\\")\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const realLLM = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const llmWithFallback = fakeLLM.withFallbacks({\\\\n\",\\n' +\n",
      "      '    \"    fallbacks: [realLLM]\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await llmWithFallback.invoke(\\\\\"你好\\\\\")\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"data\": {\\n' +\n",
      "      '      \"text/plain\": [\\n' +\n",
      "      '       \"AIMessage {\\\\n\",\\n' +\n",
      "      '       \"  lc_serializable: \\\\u001B[33mtrue\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"  lc_kwargs: {\\\\n\",\\n' +\n",
      "      '       \"    content: \\\\u001B[32m\\\\\"你好！有什么可以帮助你的吗？\\\\\"\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"    additional_kwargs: { function_call: \\\\u001B[90mundefined\\\\u001B[39m, tool_calls: \\\\u001B[90mundefined\\\\u001B[39m },\\\\n\",\\n' +\n",
      "      '       \"    response_metadata: {}\\\\n\",\\n' +\n",
      "      '       \"  },\\\\n\",\\n' +\n",
      "      '       \"  lc_namespace: [ \\\\u001B[32m\\\\\"langchain_core\\\\\"\\\\u001B[39m, \\\\u001B[32m\\\\\"messages\\\\\"\\\\u001B[39m ],\\\\n\",\\n' +\n",
      "      '       \"  content: \\\\u001B[32m\\\\\"你好！有什么可以帮助你的吗？\\\\\"\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"  name: \\\\u001B[90mundefined\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"  additional_kwargs: { function_call: \\\\u001B[90mundefined\\\\u001B[39m, tool_calls: \\\\u001B[90mundefined\\\\u001B[39m },\\\\n\",\\n' +\n",
      "      '       \"  response_metadata: {\\\\n\",\\n' +\n",
      "      '       \"    tokenUsage: { completionTokens: \\\\u001B[33m7\\\\u001B[39m, promptTokens: \\\\u001B[33m9\\\\u001B[39m, totalTokens: \\\\u001B[33m16\\\\u001B[39m },\\\\n\",\\n' +\n",
      "      '       \"    finish_reason: \\\\u001B[32m\\\\\"stop\\\\\"\\\\u001B[39m\\\\n\",\\n' +\n",
      "      '       \"  }\\\\n\",\\n' +\n",
      "      '       \"}\"\\n' +\n",
      "      \"      ]\\n\" +\n",
      "      \"     },\\n\" +\n",
      "      '     \"execution_count\": 38,\\n' +\n",
      "      '     \"metadata\": {},\\n' +\n",
      "      '     \"output_type\": \"execute_result\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 38\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": \"\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"basic-langchain.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      '  \"version\": \"3\",\\n' +\n",
      "      '  \"packages\": {\\n' +\n",
      "      '    \"specifiers\": {\\n' +\n",
      "      '      \"npm:@langchain/community\": \"npm:@langchain/community@0.0.42\",\\n' +\n",
      "      '      \"npm:@langchain/core@0.1.48\": \"npm:@langchain/core@0.1.48_zod@3.22.4\",\\n' +\n",
      "      '      \"npm:@langchain/openai@0.0.22\": \"npm:@langchain/openai@0.0.22_zod@3.22.4\",\\n' +\n",
      "      '      \"npm:cheerio\": \"npm:cheerio@1.0.0-rc.12\",\\n' +\n",
      "      '      \"npm:faiss-node\": \"npm:faiss-node@0.5.1\",\\n' +\n",
      "      '      \"npm:ignore\": \"npm:ignore@5.3.1\",\\n' +\n",
      "      '      \"npm:langchain@0.1.29\": \"npm:langchain@0.1.29_ignore@5.3.1_zod@3.22.4\",\\n' +\n",
      "      '      \"npm:pdf-parse\": \"npm:pdf-parse@1.1.1\",\\n' +\n",
      "      '      \"npm:vectordb\": \"npm:vectordb@0.4.13_@apache-arrow+ts@14.0.2_apache-arrow@14.0.2\"\\n' +\n",
      "      \"    },\\n\" +\n",
      "      '    \"npm\": {\\n' +\n",
      "      '      \"@75lb/deep-merge@1.1.1\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-xvgv6pkMGBA6GwdyJbNAnDmfAIR/DfWhrj9jgWh3TY7gRm3KO46x/GPjRg6wJ0nOepwqrNxFfojebh0Df4h4Tw==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"lodash.assignwith\": \"lodash.assignwith@4.2.0\",\\n' +\n",
      "      '          \"typical\": \"typical@7.1.1\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@anthropic-ai/sdk@0.9.1\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-wa1meQ2WSfoY8Uor3EdrJq0jTiZJoKoSii2ZVWRY1oN4Tlr5s59pADg9T79FTbPe1/se5c3pBeZgJL63wmuoBA==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@types/node\": \"@types/node@18.19.26\",\\n' +\n",
      "      '          \"@types/node-fetch\": \"@types/node-fetch@2.6.11\",\\n' +\n",
      "      '          \"abort-controller\": \"abort-controller@3.0.0\",\\n' +\n",
      "      '          \"agentkeepalive\": \"agentkeepalive@4.5.0\",\\n' +\n",
      "      '          \"digest-fetch\": \"digest-fetch@1.3.0\",\\n' +\n",
      "      '          \"form-data-encoder\": \"form-data-encoder@1.7.2\",\\n' +\n",
      "      '          \"formdata-node\": \"formdata-node@4.4.1\",\\n' +\n",
      "      '          \"node-fetch\": \"node-fetch@2.7.0\",\\n' +\n",
      "      '          \"web-streams-polyfill\": \"web-streams-polyfill@3.3.3\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@apache-arrow/ts@14.0.2\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-CtwAvLkK0CZv7xsYeCo91ml6PvlfzAmAJZkRYuz2GNBwfYufj5SVi0iuSMwIMkcU/szVwvLdzORSLa5PlF/2ug==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@types/command-line-args\": \"@types/command-line-args@5.2.0\",\\n' +\n",
      "      '          \"@types/command-line-usage\": \"@types/command-line-usage@5.0.2\",\\n' +\n",
      "      '          \"@types/node\": \"@types/node@20.3.0\",\\n' +\n",
      "      '          \"@types/pad-left\": \"@types/pad-left@2.1.1\",\\n' +\n",
      "      '          \"command-line-args\": \"command-line-args@5.2.1\",\\n' +\n",
      "      '          \"command-line-usage\": \"command-line-usage@7.0.1\",\\n' +\n",
      "      '          \"flatbuffers\": \"flatbuffers@23.5.26\",\\n' +\n",
      "      '          \"json-bignum\": \"json-bignum@0.0.3\",\\n' +\n",
      "      '          \"pad-left\": \"pad-left@2.1.0\",\\n' +\n",
      "      '          \"tslib\": \"tslib@2.6.2\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@lancedb/vectordb-darwin-arm64@0.4.13\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-JfroNCG8yKIU931Y+x8d0Fp8C9DHUSC5j+CjI+e5err7rTWtie4j3JbsXlWAnPFaFEOg0Xk3BWkSikCvhPGJGg==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@lancedb/vectordb-darwin-x64@0.4.13\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-dG6IMvfpHpnHdbJ0UffzJ7cZfMiC02MjIi6YJzgx+hKz2UNXWNBIfTvvhqli85mZsGRXL1OYDdYv0K1YzNjXlA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@lancedb/vectordb-linux-arm64-gnu@0.4.13\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-BRR1VzaMviXby7qmLm0axNZM8eUZF3ZqfvnDKdVRpC3LaRueD6pMXHuC2IUKaFkn7xktf+8BlDZb6foFNEj8bQ==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@lancedb/vectordb-linux-x64-gnu@0.4.13\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-WnekZ7ZMlria+NODZ6aBCljCFQSe2bBNUS9ZpyFl/Y1vHduSQPuBxM6V7vp2QubC0daq/rifgjDob89DF+x3xw==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@lancedb/vectordb-win32-x64-msvc@0.4.13\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-3NDpMWBL2ksDHXAraXhowiLqQcNWM5bdbeHwze4+InYMD54hyQ2ODNc+4usxp63Nya9biVnFS27yXULqkzIEqQ==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@langchain/community@0.0.42\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-Xp3H0w23X9viHRpb3GUiFl+qjB68h/V7ztPOxR1AtaKlmXkjrSwiLqhMjlVsJ9jyPaKIr5ZOV07gYAXJUz/P8Q==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@langchain/core\": \"@langchain/core@0.1.48_zod@3.22.4\",\\n' +\n",
      "      '          \"@langchain/openai\": \"@langchain/openai@0.0.23_zod@3.22.4\",\\n' +\n",
      "      '          \"expr-eval\": \"expr-eval@2.0.2\",\\n' +\n",
      "      '          \"flat\": \"flat@5.0.2\",\\n' +\n",
      "      '          \"langsmith\": \"langsmith@0.1.13\",\\n' +\n",
      "      '          \"uuid\": \"uuid@9.0.1\",\\n' +\n",
      "      '          \"zod\": \"zod@3.22.4\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@langchain/core@0.1.48_zod@3.22.4\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-kGggyDbaYzCIPGkzvMvm/v0+lcTy1jlX6QZ7PSzUQFYJg5JK399x3AOYIDkbbUVxBAyHRgrWlxVQXH0FW3N6Bg==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"ansi-styles\": \"ansi-styles@5.2.0\",\\n' +\n",
      "      '          \"camelcase\": \"camelcase@6.3.0\",\\n' +\n",
      "      '          \"decamelize\": \"decamelize@1.2.0\",\\n' +\n",
      "      '          \"js-tiktoken\": \"js-tiktoken@1.0.10\",\\n' +\n",
      "      '          \"langsmith\": \"langsmith@0.1.13\",\\n' +\n",
      "      '          \"ml-distance\": \"ml-distance@4.0.1\",\\n' +\n",
      "      '          \"p-queue\": \"p-queue@6.6.2\",\\n' +\n",
      "      '          \"p-retry\": \"p-retry@4.6.2\",\\n' +\n",
      "      '          \"uuid\": \"uuid@9.0.1\",\\n' +\n",
      "      '          \"zod\": \"zod@3.22.4\",\\n' +\n",
      "      '          \"zod-to-json-schema\": \"zod-to-json-schema@3.22.4_zod@3.22.4\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@langchain/openai@0.0.22_zod@3.22.4\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-mkXRSeedwCzPnfvp1kvaGBXyVWTB86n77pUyw5bC9ka43/cPBHZdHlSnTZMuJi3H4RnV4CMxunaOlm+s7NWfxQ==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@langchain/core\": \"@langchain/core@0.1.48_zod@3.22.4\",\\n' +\n",
      "      '          \"js-tiktoken\": \"js-tiktoken@1.0.10\",\\n' +\n",
      "      '          \"openai\": \"openai@4.29.2\",\\n' +\n",
      "      '          \"zod\": \"zod@3.22.4\",\\n' +\n",
      "      '          \"zod-to-json-schema\": \"zod-to-json-schema@3.22.4_zod@3.22.4\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@langchain/openai@0.0.23_zod@3.22.4\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-H5yv2hKQ5JVa6jC1wQxiN2299lJbPc5JUv93c6IUw+0jr0kFqH48NWbcythz1UFj2rOpZdaFJSYJs2nr9bhVLg==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@langchain/core\": \"@langchain/core@0.1.48_zod@3.22.4\",\\n' +\n",
      "      '          \"js-tiktoken\": \"js-tiktoken@1.0.10\",\\n' +\n",
      "      '          \"openai\": \"openai@4.29.2\",\\n' +\n",
      "      '          \"zod\": \"zod@3.22.4\",\\n' +\n",
      "      '          \"zod-to-json-schema\": \"zod-to-json-schema@3.22.4_zod@3.22.4\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@neon-rs/load@0.0.74\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-/cPZD907UNz55yrc/ud4wDgQKtU1TvkD9jeqZWG6J4IMmZkp6zgjkQcKA8UvpkZlcpPHvc8J17sGzLFbP/LUYg==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/command-line-args@5.2.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-UuKzKpJJ/Ief6ufIaIzr3A/0XnluX7RvFgwkV89Yzvm77wCh1kFaFmqN8XEnGcN62EuHdedQjEMb8mYxFLGPyA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/command-line-usage@5.0.2\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-n7RlEEJ+4x4TS7ZQddTmNSxP+zziEG0TNsMfiRIxcIVXt71ENJ9ojeXmGO3wPoTdn7pJcU2xc3CJYMktNT6DPg==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/node-fetch@2.6.11\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-24xFj9R5+rfQJLRyM56qh+wnVSYhyXC2tkoBndtY0U+vubqNsYXGjufB2nn8Q6gt0LrARwL6UBtMCSVCwl4B1g==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@types/node\": \"@types/node@18.16.19\",\\n' +\n",
      "      '          \"form-data\": \"form-data@4.0.0\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/node@18.16.19\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-IXl7o+R9iti9eBW4Wg2hx1xQDig183jj7YLn8F7udNceyfkbn1ZxmzZXuak20gR40D7pIkIY1kYGx5VIGbaHKA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/node@18.19.26\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-+wiMJsIwLOYCvUqSdKTrfkS8mpTp+MPINe6+Np4TAGFWWRWiBQ5kSq9nZGCSPkzx9mvT+uEukzpX4MOSCydcvw==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"undici-types\": \"undici-types@5.26.5\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/node@20.3.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-cumHmIAf6On83X7yP+LrsEyUOf/YlociZelmpRYaGFydoaPdxdt80MAbu6vWerQT2COCp2nPvHdsbD7tHn/YlQ==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/pad-left@2.1.1\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-Xd22WCRBydkGSApl5Bw0PhAOHKSVjNL3E3AwzKaps96IMraPqy5BvZIsBVK6JLwdybUzjHnuWVwpDd0JjTfHXA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/retry@0.12.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-wWKOClTTiizcZhXnPY4wikVAwmdYHp8q6DmC+EJUzAMsycb7HB32Kh9RN4+0gExjmPmZSAQjgURXIGATPegAvA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"@types/uuid@9.0.8\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-jg+97EGIcY9AGHJJRaaPVgetKDsrTgbRjQ5Msgjh/DQKEFl0DtyRr/VCOyD1T2R1MNeWPK/u7JoGhlDZnKBAfA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"abort-controller@3.0.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-h8lQ8tacZYnR3vNQTgibj+tODHI5/+l06Au2Pcriv/Gmet0eaj4TwWH41sO9wnHDiQsEj19q0drzdWdeAHtweg==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"event-target-shim\": \"event-target-shim@5.0.1\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"agentkeepalive@4.5.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-5GG/5IbQQpC9FpkRGsSvZI5QYeSCzlJHdpBQntCsuTOxhKD8lqKhrleg2Yi7yvMIf82Ycmmqln9U8V9qwEiJew==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"humanize-ms\": \"humanize-ms@1.2.1\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"ansi-styles@4.3.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-zbB9rCJAT1rbjiVDb2hqKFHNYLxgtk8NURxZ3IZwD3F6NtxbXZQCnnSi1Lkx+IDohdPlFp222wVALIheZJQSEg==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"color-convert\": \"color-convert@2.0.1\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"ansi-styles@5.2.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-Cxwpt2SfTzTtXcfOlzGEee8O+c+MmUgGrNiBcXnuWxuFJHe6a5Hz7qwhwe5OgaSYI0IJvkLqWX1ASG+cJOkEiA==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"apache-arrow@14.0.2\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-EBO2xJN36/XoY81nhLcwCJgFwkboDZeyNQ+OPsG7bCoQjc2BT0aTyH/MR6SrL+LirSNz+cYqjGRlupMMlP1aEg==\",\\n' +\n",
      "      '        \"dependencies\": {\\n' +\n",
      "      '          \"@types/command-line-args\": \"@types/command-line-args@5.2.0\",\\n' +\n",
      "      '          \"@types/command-line-usage\": \"@types/command-line-usage@5.0.2\",\\n' +\n",
      "      '          \"@types/node\": \"@types/node@20.3.0\",\\n' +\n",
      "      '          \"@types/pad-left\": \"@types/pad-left@2.1.1\",\\n' +\n",
      "      '          \"command-line-args\": \"command-line-args@5.2.1\",\\n' +\n",
      "      '          \"command-line-usage\": \"command-line-usage@7.0.1\",\\n' +\n",
      "      '          \"flatbuffers\": \"flatbuffers@23.5.26\",\\n' +\n",
      "      '          \"json-bignum\": \"json-bignum@0.0.3\",\\n' +\n",
      "      '          \"pad-left\": \"pad-left@2.1.0\",\\n' +\n",
      "      '          \"tslib\": \"tslib@2.6.2\"\\n' +\n",
      "      \"        }\\n\" +\n",
      "      \"      },\\n\" +\n",
      "      '      \"argparse@2.0.1\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-8+9WqebbFzpX9OR+Wa6O29asIogeRMzcGtAINdpMHHyAg10f05aSFVBbcEqGf/PXw1EjAZ+q2/bEBg3DvurK3Q==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"array-back@3.1.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-TkuxA4UCOvxuDK6NZYXCalszEzj+TLszyASooky+i742l9TqsOdYCMJJupxRic61hwquNtppB3hgcuq9SVSH1Q==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"array-back@6.2.2\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-gUAZ7HPyb4SJczXAMUXMGAvI976JoK3qEx9v1FTmeYuJj0IBiaKttG1ydtGKdkfqWkIkouke7nG8ufGy77+Cvw==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"asynckit@0.4.0\": {\\n' +\n",
      "      '        \"integrity\": \"sha512-Oei9OH4tRh0YqU3GxhX79dM/mwVgvbZJaSNaRk+bshkj0S5cfHcgYakreBjrHwatXKbz+IoIdYLxrKim2MjW0Q==\",\\n' +\n",
      "      '        \"dependencies\": {}\\n' +\n",
      "      \"      },\\n\" +\n",
      "      '      \"axios@1.6.8\": {\\n' +\n",
      "      '        \"integr'... 35829 more characters,\n",
      "    metadata: {\n",
      "      source: \"deno.lock\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"11ee0f16-747d-463b-ba59-f6a22fc13d1e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"cd1f52e3-98ec-4277-aae8-560dc36cb492\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { z } from \\\\\"zod\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"// 简单使用\\\\n\",\\n' +\n",
      "      '    \"const stringSchema = z.string();\\\\n\",\\n' +\n",
      "      '    \"stringSchema.parse(\\\\\"Hello, Zod!\\\\\");\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"f3362645-bc52-4ca0-8718-4fca2905914b\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"stringSchema.parse(2323);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"79d2ea09-ec90-4592-992b-2e5635f39cb1\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"// 基础类型\\\\n\",\\n' +\n",
      "      '    \"const stringSchema = z.string();\\\\n\",\\n' +\n",
      "      '    \"const numberSchema = z.number();\\\\n\",\\n' +\n",
      "      '    \"const booleanSchema = z.boolean();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"// 数组\\\\n\",\\n' +\n",
      "      '    \"const stringArraySchema = z.array(z.string());\\\\n\",\\n' +\n",
      "      '    \"stringArraySchema.parse([\\\\\"apple\\\\\", \\\\\"banana\\\\\", \\\\\"cherry\\\\\"]); \\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"// 对象\\\\n\",\\n' +\n",
      "      '    \"const personSchema = z.object({\\\\n\",\\n' +\n",
      "      '    \"  name: z.string(),\\\\n\",\\n' +\n",
      "      '    \"  age: z.number(),\\\\n\",\\n' +\n",
      "      '    \"  // 可选类型\\\\n\",\\n' +\n",
      "      '    \"  isStudent: z.boolean().optional(),\\\\n\",\\n' +\n",
      "      '    \"  // 默认值\\\\n\",\\n' +\n",
      "      '    \"  home: z.string().default(\\\\\"no home\\\\\")\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"// 联合类型\\\\n\",\\n' +\n",
      "      '    \"const mixedTypeSchema = z.union([z.string(), z.number()]);\\\\n\",\\n' +\n",
      "      '    \"mixedTypeSchema.parse(\\\\\"hello\\\\\"); \\\\n\",\\n' +\n",
      "      '    \"mixedTypeSchema.parse(42); \"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"356243dc-0e87-45c6-a66b-9b4149f4fb4f\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { z } from \\\\\"zod\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const getCurrentWeatherSchema = z.object({\\\\n\",\\n' +\n",
      "      '    \"  location: z.string().describe(\\\\\"The city and state, e.g. San Francisco, CA\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"  unit: z.enum([\\\\\"celsius\\\\\", \\\\\"fahrenheit\\\\\"]).describe(\\\\\"The unit of temperature\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"b8a9a882-c08a-431a-aea2-6062773ac532\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { zodToJsonSchema } from \\\\\"zod-to-json-schema\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const paramSchema = zodToJsonSchema(getCurrentWeatherSchema)\\\\n\",\\n' +\n",
      "      '    \"paramSchema\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"63fc3643-a7d7-437a-b474-45ca7d72ba3a\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0 \\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const modelWithTools = model.bind({\\\\n\",\\n' +\n",
      "      '    \"    tools: [\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"getCurrentWeather\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"Get the current weather in a given location\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(getCurrentWeatherSchema),\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    ]\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await modelWithTools.invoke(\\\\\"北京的天气怎么样\\\\\");\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"d9683945-c0de-4bf0-b1e3-28f8190ab943\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatPromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", \\\\\"You are a helpful assistant\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"human\\\\\", \\\\\"{input}\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(modelWithTools)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"北京的天气怎么样\\\\\"\\\\n\",\\n' +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"a960463a-c711-4a60-8965-7a7c8b65f336\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const getCurrentTimeSchema = z.object({\\\\n\",\\n' +\n",
      "      '    \"  format: z\\\\n\",\\n' +\n",
      "      '    \"    .enum([\\\\\"iso\\\\\", \\\\\"locale\\\\\", \\\\\"string\\\\\"])\\\\n\",\\n' +\n",
      "      '    \"    .optional()\\\\n\",\\n' +\n",
      "      '    \"    .describe(\\\\\"The format of the time, e.g. iso, locale, string\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"zodToJsonSchema(getCurrentTimeSchema)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"5194e71a-37a4-4339-9e91-2e1b7847d3f7\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0 \\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const modelWithMultiTools = model.bind({\\\\n\",\\n' +\n",
      "      '    \"    tools: [\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"getCurrentWeather\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"Get the current weather in a given location\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(getCurrentWeatherSchema)\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        },\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"getCurrentTime\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"Get the current time in a given format\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(getCurrentTimeSchema)\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    ]\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await modelWithMultiTools.invoke(\\\\\"现在几点了？\\\\\");\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"e6256e6a-a433-4368-a65b-b2fb3bedca68\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await modelWithMultiTools.invoke(\\\\\"现在 iso 格式的时间是什么？\\\\\");\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"50a931ec-a737-4472-a3a4-cbb72aecd192\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0 \\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const modelWithForce = model.bind({\\\\n\",\\n' +\n",
      "      '    \"    tools: [\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"getCurrentWeather\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"Get the current weather in a given location\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(getCurrentWeatherSchema)\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        },\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"getCurrentTime\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"Get the current time in a given format\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(getCurrentTimeSchema)\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    ],\\\\n\",\\n' +\n",
      "      '    \"    tool_choice: {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"           name: \\\\\"getCurrentWeather\\\\\"\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await modelWithForce.invoke(\\\\\"现在几点了？\\\\\");\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"id\": \"c54e4e1e-40bc-41cb-969b-c01efb2882c5\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## Tagging\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"b04f0485-eae1-462e-940d-9261edc38f29\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const taggingSchema = z.object({\\\\n\",\\n' +\n",
      "      '    \"  emotion:z.enum([\\\\\"pos\\\\\", \\\\\"neg\\\\\", \\\\\"neutral\\\\\"]).describe(\\\\\"文本的情感\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"  language: z.string().describe(\\\\\"文本的核心语言（应为ISO 639-1代码）\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"ed1fdd8e-872c-4feb-9a42-47063f11d647\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { JsonOutputToolsParser } from \\\\\"@langchain/core/output_parsers/openai_tools\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    temperature: 0 \\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const modelTagging = model.bind({\\\\n\",\\n' +\n",
      "      '    \"    tools: [\\\\n\",\\n' +\n",
      "      '    \"        {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            function: {\\\\n\",\\n' +\n",
      "      '    \"                name: \\\\\"tagging\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"为特定的文本片段打上标签\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                parameters: zodToJsonSchema(taggingSchema)\\\\n\",\\n' +\n",
      "      '    \"            }\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    ],\\\\n\",\\n' +\n",
      "      '    \"    tool_choice: {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"           name: \\\\\"tagging\\\\\"\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", \\\\\"仔细思考，你有充足的时间进行严谨的思考，然后按照指示对文本进行标记\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"human\\\\\", \\\\\"{input}\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(modelTagging).pipe(new JsonOutputToolsParser())\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"1c87749a-b8b7-4909-b59e-29a9f8dfbab0\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"hello world\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"1cf4ec15-b0f3-4541-8a66-32bbbd7392ef\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"写代码太难了，👴 不干了\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"6f81d723-ef03-4c30-a49a-7454bf6ee1c8\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    // 日语，圣诞快乐\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"メリークリスマス!\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"36a04165-3f34-439d-a036-601d96a5ddd5\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"我非常喜欢 AI，特别是 LLM，因为它非常 powerful\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"id\": \"a3f2ed88-24fa-4192-91c8-990b5c16184e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## Extraction\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"6934498f-ba55-4276-8430-f661f76211ed\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const personExtracti'... 3265 more characters,\n",
      "    metadata: {\n",
      "      source: \"lc-tools.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const text = await Deno.readTextFile(\\\\\"./data/qiu.txt\\\\\");\\\\n\",\\n' +\n",
      "      '    \"const text = \\\\\"abc\\\\\"\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"id\": \"c1baeaa15b65f2e6\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"source\": \"text\",\\n' +\n",
      "      '   \"id\": \"5f4637887fa946de\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"source\": \"\",\\n' +\n",
      "      '   \"id\": \"f3da9ef97e425a7c\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:08:01.398897Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:08:01.395721Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const lines = text.split(\\\\\"\\\\\\\\r\\\\\")\\\\n\",\\n' +\n",
      "      '    \"lines\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"id\": \"58503b710859eeb3\",\\n' +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"ename\": \"SyntaxError\",\\n' +\n",
      "      '     \"evalue\": \"invalid syntax (2584469611.py, line 1)\",\\n' +\n",
      "      '     \"output_type\": \"error\",\\n' +\n",
      "      '     \"traceback\": [\\n' +\n",
      "      '      \"\\\\u001B[0;36m  Cell \\\\u001B[0;32mIn[1], line 1\\\\u001B[0;36m\\\\u001B[0m\\\\n\\\\u001B[0;31m    const lines = text.split(\\\\\"\\\\\\\\r\\\\\")\\\\u001B[0m\\\\n\\\\u001B[0m          ^\\\\u001B[0m\\\\n\\\\u001B[0;31mSyntaxError\\\\u001B[0m\\\\u001B[0;31m:\\\\u001B[0m invalid syntax\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 1\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"source\": \"# Deno 测试\",\\n' +\n",
      "      '   \"id\": \"615af63c594707fc\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:08:04.039110Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:08:04.036864Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": \"import _ from \\\\\"npm:/lodash@4.17.21\\\\\"\",\\n' +\n",
      "      '   \"id\": \"87a0b17fb5a66965\",\\n' +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"ename\": \"SyntaxError\",\\n' +\n",
      "      '     \"evalue\": \"invalid syntax (358535826.py, line 1)\",\\n' +\n",
      "      '     \"output_type\": \"error\",\\n' +\n",
      "      '     \"traceback\": [\\n' +\n",
      "      '      \"\\\\u001B[0;36m  Cell \\\\u001B[0;32mIn[2], line 1\\\\u001B[0;36m\\\\u001B[0m\\\\n\\\\u001B[0;31m    import _ from \\\\\"npm:/lodash@4.17.21\\\\\"\\\\u001B[0m\\\\n\\\\u001B[0m             ^\\\\u001B[0m\\\\n\\\\u001B[0;31mSyntaxError\\\\u001B[0m\\\\u001B[0;31m:\\\\u001B[0m invalid syntax\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 2\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:08:05.203908Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:08:05.199032Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const a = _.random(0, 5);\\\\n\",\\n' +\n",
      "      '    \"a\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"id\": \"bdb753c58753499c\",\\n' +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"ename\": \"SyntaxError\",\\n' +\n",
      "      '     \"evalue\": \"invalid syntax (791589692.py, line 1)\",\\n' +\n",
      "      '     \"output_type\": \"error\",\\n' +\n",
      "      '     \"traceback\": [\\n' +\n",
      "      '      \"\\\\u001B[0;36m  Cell \\\\u001B[0;32mIn[3], line 1\\\\u001B[0;36m\\\\u001B[0m\\\\n\\\\u001B[0;31m    const a = _.random(0, 5);\\\\u001B[0m\\\\n\\\\u001B[0m          ^\\\\u001B[0m\\\\n\\\\u001B[0;31mSyntaxError\\\\u001B[0m\\\\u001B[0;31m:\\\\u001B[0m invalid syntax\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 3\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:08:06.050862Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:08:06.048464Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": \"\",\\n' +\n",
      "      '   \"id\": \"9dfc4c158d772f54\",\\n' +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"ename\": \"SyntaxError\",\\n' +\n",
      "      '     \"evalue\": \"invalid syntax (705170268.py, line 1)\",\\n' +\n",
      "      '     \"output_type\": \"error\",\\n' +\n",
      "      '     \"traceback\": [\\n' +\n",
      "      '      \"\\\\u001B[0;36m  Cell \\\\u001B[0;32mIn[4], line 1\\\\u001B[0;36m\\\\u001B[0m\\\\n\\\\u001B[0;31m    import _ from \\\\\"lodash\\\\\"\\\\u001B[0m\\\\n\\\\u001B[0m             ^\\\\u001B[0m\\\\n\\\\u001B[0;31mSyntaxError\\\\u001B[0m\\\\u001B[0;31m:\\\\u001B[0m invalid syntax\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 4\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Python 3 (ipykernel)\",\\n' +\n",
      "      '   \"language\": \"python\",\\n' +\n",
      "      '   \"name\": \"python3\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 5\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"learn-notebook-basic.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { Document } from \\\\\"langchain/document\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const test = new Document({ pageContent: \\\\\"test text\\\\\", metadata: { source: \\\\\"ABC Title\\\\\" } });\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"test\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { TextLoader } from \\\\\"langchain/document_loaders/fs/text\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const loader = new TextLoader(\\\\\"data/qiu.txt\\\\\");\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(docs)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import * as pdfParse from \\\\\"pdf-parse\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { PDFLoader } from \\\\\"langchain/document_loaders/fs/pdf\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const loader = new PDFLoader(\\\\\"data/github-copliot.pdf\\\\\");\\\\n\",\\n' +\n",
      "      '    \"const pdfs = await loader.load()\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"pdfs\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const loader = new PDFLoader(\\\\\"data/github-copliot.pdf\\\\\", { splitPages: false });\\\\n\",\\n' +\n",
      "      '    \"const pdf = await loader.load()\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"pdf\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"pdf[0]\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { GithubRepoLoader } from \\\\\"langchain/document_loaders/web/github\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import ignore from \\\\\"ignore\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const loader = new GithubRepoLoader(\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"https://github.com/zhaomo08/langchainjs-juejin\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    { \\\\n\",\\n' +\n",
      "      '    \"        branch: \\\\\"main\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        recursive: false, \\\\n\",\\n' +\n",
      "      '    \"        unknown: \\\\\"warn\\\\\", \\\\n\",\\n' +\n",
      "      '    \"        ignorePaths: [\\\\\"*.md\\\\\", \\\\\"yarn.lock\\\\\", \\\\\"*.json\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"        accessToken: env[\\\\\"GITHUB_TOKEN\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"  );\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const docs = await loader.load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(docs)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"docs.length\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import \\\\\"cheerio\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { CheerioWebBaseLoader } from \\\\\"langchain/document_loaders/web/cheerio\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const loader = new CheerioWebBaseLoader(\\\\n\",\\n' +\n",
      "      '    \"  \\\\\"https://kaiyi.cool/blog/github-copilot\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  {\\\\n\",\\n' +\n",
      "      '    \"    selector: \\\\\"h3\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  }\\\\n\",\\n' +\n",
      "      '    \");\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(docs[0].pageContent)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:46:09.775316Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:46:09.771849Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 5\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:46:12.955569Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:46:10.874387Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { SerpAPILoader } from \\\\\"langchain/document_loaders/web/serpapi\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const apiKey = env[\\\\\"SERP_KEY\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"const question = \\\\\"什么 github copliot\\\\\"\\\\n\",\\n' +\n",
      "      '    \"const loader = new SerpAPILoader({ q: question, apiKey });\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 6\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:46:15.803779Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:46:15.803063Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(docs[1].pageContent)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"{\\\\\"position\\\\\":1,\\\\\"title\\\\\":\\\\\"什么是GitHub Copilot？ [共6 个]\\\\\",\\\\\"link\\\\\":\\\\\"https://learn.microsoft.com/zh-cn/shows/introduction-to-github-copilot/what-is-github-copilot-1-of-6\\\\\",\\\\\"redirect_link\\\\\":\\\\\"https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://learn.microsoft.com/zh-cn/shows/introduction-to-github-copilot/what-is-github-copilot-1-of-6&ved=2ahUKEwjjgcuDqqSGAxW7FlkFHTlYDtYQFnoECB4QAQ\\\\\",\\\\\"displayed_link\\\\\":\\\\\"https://learn.microsoft.com › shows\\\\\",\\\\\"favicon\\\\\":\\\\\"https://serpapi.com/searches/664f80e3c56d93e90aed5886/images/82277c65fb25b02675bdb085dc6a1332ae409164795d97236ae0a852bef5c20c.png\\\\\",\\\\\"date\\\\\":\\\\\"Mar 9, 2023\\\\\",\\\\\"snippet\\\\\":\\\\\"GitHub Copilot 是AI 编码搭档，可在你编码时提供自动完成建议。 通过键入代码或用自然语言描述代码来获取建议。 Copilot 分析文件和相关文件，并在 ...\\\\\",\\\\\"snippet_highlighted_words\\\\\":[\\\\\"GitHub Copilot\\\\\",\\\\\"Copilot\\\\\"],\\\\\"source\\\\\":\\\\\"Microsoft Learn\\\\\"}\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 7\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"source\": \"\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"loader.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"99d4e05f-8ab3-423e-826f-510c1d8d9c7e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"bd0df1a9-372e-42c3-b6e5-c899197ba7eb\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { BufferMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationChain } from \\\\\"langchain/chains\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const memory = new BufferMemory();\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ llm: chatModel, memory: memory, verbose: true });\\\\n\",\\n' +\n",
      "      '    \"const res1 = await chain.call({ input: \\\\\"我是小明\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"2c57bf9c-9ce9-411c-b7b6-cc55d6d8743c\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res1\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"493ac179-0863-4677-a69f-346a43436ea7\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chain.call({ input: \\\\\"我叫什么？\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"5d6253e8-40fb-4772-b781-168298085b5a\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res2\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"6b8077dc-9a9a-48c2-a13c-a88f2a94a76c\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { BufferWindowMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationChain } from \\\\\"langchain/chains\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const memory = new BufferWindowMemory({ k: 1 });\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ llm: model, memory: memory });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"30e70614-888b-431e-ab0b-9407cd670d51\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ConversationSummaryMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { PromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const memory = new ConversationSummaryMemory({\\\\n\",\\n' +\n",
      "      '    \"    memoryKey: \\\\\"summary\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    llm: new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"          verbose: true,\\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const prompt = PromptTemplate.fromTemplate(`\\\\n\",\\n' +\n",
      "      '    \"你是一个乐于助人的助手。尽你所能回答所有问题。\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"这是聊天记录的摘要:\\\\n\",\\n' +\n",
      "      '    \"{summary}\\\\n\",\\n' +\n",
      "      '    \"Human: {input}\\\\n\",\\n' +\n",
      "      '    \"AI:`);\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ llm: model, prompt, memory, verbose: true });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"21221a69-02c2-4bac-b27b-56ffcd015740\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res1 = await chain.call({ input: \\\\\"我是小明\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"53d89513-faf5-4093-929b-76bc3a38a59d\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chain.call({ input: \\\\\"我叫什么？\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"b988d5dd-bf44-4d52-8380-f179059694f6\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationSummaryBufferMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationChain } from \\\\\"langchain/chains\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const memory = new ConversationSummaryBufferMemory({\\\\n\",\\n' +\n",
      "      '    \"  llm: new ChatOpenAI(),\\\\n\",\\n' +\n",
      "      '    \"  maxTokenLimit: 200\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ llm: model, memory: memory, verbose: true });\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"c856db57-7ca2-4005-8160-54e0bf61c4b3\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res1 = await chain.call({ input: \\\\\"我是小明\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"14948a02-2c4d-4269-9a81-aab2af9e3495\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chain.call({ input: \\\\\"我叫什么？\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"9b750490-ee19-48c4-99b9-8d511d16ea5f\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { EntityMemory, ENTITY_MEMORY_CONVERSATION_TEMPLATE } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationChain } from \\\\\"langchain/chains\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const memory = new EntityMemory({\\\\n\",\\n' +\n",
      "      '    \"    llm: new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"        verbose: true \\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"    chatHistoryKey: \\\\\"history\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    entitiesKey: \\\\\"entities\\\\\"\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ \\\\n\",\\n' +\n",
      "      '    \"    llm: model, \\\\n\",\\n' +\n",
      "      '    \"    prompt: ENTITY_MEMORY_CONVERSATION_TEMPLATE,\\\\n\",\\n' +\n",
      "      '    \"    memory: memory, \\\\n\",\\n' +\n",
      "      '    \"    verbose: true \\\\n\",\\n' +\n",
      "      '    \"});\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"79a8928d-c265-4f8d-b7be-ca770aa94ad9\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res1 = await chain.call({ input: \\\\\"我叫小明，今年 18 岁\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"d2d5d7ff-5e8b-4957-86a3-90680ead06be\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chain.call({ input: \\\\\"ABC 是一家互联网公司，主要是售卖方便面的公司\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"7f215e7a-9d5d-4ebf-bfd5-386bf659dbd2\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res3 = await chain.call({ input: \\\\\"介绍小明\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"1e52d2ed-cb69-44f5-afd6-f1ac490af1b8\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res3 = await chain.call({ input: \\\\\"介绍小明和 ABC\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"7caf9f39-eed8-4662-af39-1f630350ef23\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const test1 = await memory.loadMemoryVariables({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"介绍小明和 ABC\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"fac64626-1cb4-457a-ad56-a17ecf58d23c\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": []\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 5\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"memory-2.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"2fbb379b-b1b9-4dae-8b28-21a3ed27f8d0\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"a6c0f656-a1f8-4741-aeeb-28566c0b8f8e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RunnableSequence } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RunnablePassthrough } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { BufferMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatPromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"4f05384f-e7fc-465f-a7aa-4a2779ad424a\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    verbose:true\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const memory = new BufferMemory();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const TEMPLATE = `\\\\n\",\\n' +\n",
      "      '    \"你是一个乐于助人的 ai 助手。尽你所能回答所有问题。\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"这是跟人类沟通的聊天历史:\\\\n\",\\n' +\n",
      "      '    \"{history}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"据此回答人类的问题:\\\\n\",\\n' +\n",
      "      '    \"{input}\\\\n\",\\n' +\n",
      "      '    \"`\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromTemplate(TEMPLATE);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"dd5d7b4c-6691-4e38-9f19-fa7d60616247\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"let tempInput = \\\\\"\\\\\"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain =  RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        input: new RunnablePassthrough(),\\\\n\",\\n' +\n",
      "      '    \"        memoryObject: async (input) => {\\\\n\",\\n' +\n",
      "      '    \"            const history = await memory.loadMemoryVariables({\\\\n\",\\n' +\n",
      "      '    \"                input\\\\n\",\\n' +\n",
      "      '    \"            })\\\\n\",\\n' +\n",
      "      '    \"            tempInput = input\\\\n\",\\n' +\n",
      "      '    \"            return history\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    RunnablePassthrough.assign({\\\\n\",\\n' +\n",
      "      '    \"        history: (input) => input.memoryObject.history\\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"    prompt,\\\\n\",\\n' +\n",
      "      '    \"    new RunnablePassthrough({\\\\n\",\\n' +\n",
      "      '    \"        func: (input) => console.log(input)\\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"    chatModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"    new RunnablePassthrough({\\\\n\",\\n' +\n",
      "      '    \"        func: async (output) => {\\\\n\",\\n' +\n",
      "      '    \"            await memory.saveContext({\\\\n\",\\n' +\n",
      "      '    \"                input: tempInput\\\\n\",\\n' +\n",
      "      '    \"            }, {\\\\n\",\\n' +\n",
      "      '    \"                output\\\\n\",\\n' +\n",
      "      '    \"            })\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"]);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"d7a38687-3609-4e07-84e7-8edff1be14f4\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke(\\\\\"你好, 我叫小明\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"0e1f9e21-f7a0-4a74-8fa7-2e45ce71a32f\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chain.invoke(\\\\\"我叫什么？\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"id\": \"3b0f54de-55a1-4e9b-92e6-605c93b5861e\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## 实现自定义的 chat history\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"82fb5f88-b880-40cb-8c4a-3ff1eb0a97ed\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { JSONChatHistory } from \\\\\"./JSONChatHistory/index.ts\\\\\"\\\\n\",\\n' +\n",
      "      '    \"import { AIMessage, HumanMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const history = new JSONChatHistory({\\\\n\",\\n' +\n",
      "      '    \"    dir: \\\\\"chat_data\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    sessionId: \\\\\"test\\\\\"\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await history.addMessages([\\\\n\",\\n' +\n",
      "      '    \"  new HumanMessage(\\\\\"Hi, 我叫小明\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"  new AIMessage(\\\\\"你好\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"]);\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const messages = await history.getMessages();\\\\n\",\\n' +\n",
      "      '    \"console.log(messages)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"b883403c-f99a-4ff4-b7bc-2f64068b0286\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { BufferMemory } from \\\\\"langchain/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ConversationChain } from \\\\\"langchain/chains\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const memory = new BufferMemory({\\\\n\",\\n' +\n",
      "      '    \"    chatHistory: history\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const chain = new ConversationChain({ llm: chatModel, memory: memory });\\\\n\",\\n' +\n",
      "      '    \"const res1 = await chain.call({ input: \\\\\"我叫什么？\\\\\" });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"590b0825-2753-4773-a739-ae0a777d7460\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res1\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"1198a30d-2f2f-4ee2-9569-498071904a9a\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const messages = await history.getMessages()\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"id\": \"eb695ac8-a744-4685-914e-aad6bdb87be8\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"messages\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 5\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"memory-3.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## ChatMessageHistory\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatMessageHistory } from \\\\\"langchain/stores/message/in_memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage, AIMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const history = new ChatMessageHistory();\\\\n\",\\n' +\n",
      "      '    \"await history.addMessage(new HumanMessage(\\\\\"hi\\\\\"));\\\\n\",\\n' +\n",
      "      '    \"await history.addMessage(new AIMessage(\\\\\"What can I do for you?\\\\\"));\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const messages = await history.getMessages();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(messages);\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## 手动维护 chat history\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatPromptTemplate, MessagesPlaceholder } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", `You are a helpful assistant. Answer all questions to the best of your ability.\\\\n\",\\n' +\n",
      "      '    \"    You are talkative and provides lots of specific details from its context. \\\\n\",\\n' +\n",
      "      '    \"    If the you does not know the answer to a question, it truthfully says you do not know.`],\\\\n\",\\n' +\n",
      "      '    \"    new MessagesPlaceholder(\\\\\"history_message\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"]);\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(chatModel);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatMessageHistory } from \\\\\"langchain/stores/message/in_memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage, AIMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const history = new ChatMessageHistory();\\\\n\",\\n' +\n",
      "      '    \"await history.addMessage(new HumanMessage(\\\\\"hi, my name is Kai\\\\\"));\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const res1 = await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    history_message: await history.getMessages()\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res1\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await history.addMessage(res1)\\\\n\",\\n' +\n",
      "      '    \"await history.addMessage(new HumanMessage(\\\\\"What is my name?\\\\\"));\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await history.getMessages()\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    history_message: await history.getMessages()\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res2\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(res2.content)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## 自动维护 chat history\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RunnableWithMessageHistory } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatPromptTemplate, MessagesPlaceholder } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatMessageHistory } from \\\\\"langchain/stores/message/in_memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", \\\\\"You are a helpful assistant. Answer all questions to the best of your ability.\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    new MessagesPlaceholder(\\\\\"history_message\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"human\\\\\",\\\\\"{input}\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"]);\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const history = new ChatMessageHistory();\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(chatModel)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chainWithHistory = new RunnableWithMessageHistory({\\\\n\",\\n' +\n",
      "      '    \"  runnable: chain,\\\\n\",\\n' +\n",
      "      '    \"  getMessageHistory: (_sessionId) => history,\\\\n\",\\n' +\n",
      "      '    \"  inputMessagesKey: \\\\\"input\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  historyMessagesKey: \\\\\"history_message\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res1 = await chainWithHistory.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"hi, my name is Kai\\\\\"\\\\n\",\\n' +\n",
      "      '    \"},{\\\\n\",\\n' +\n",
      "      '    \"    configurable: { sessionId: \\\\\"none\\\\\" }\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res1\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res2 = await chainWithHistory.invoke({\\\\n\",\\n' +\n",
      "      '    \"    input: \\\\\"我的名字叫什么？\\\\\"\\\\n\",\\n' +\n",
      "      '    \"},{\\\\n\",\\n' +\n",
      "      '    \"    configurable: { sessionId: \\\\\"none\\\\\" }\\\\n\",\\n' +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res2\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await history.getMessages()\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"markdown\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"## 自动生成 chat history 摘要\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RunnableWithMessageHistory } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatPromptTemplate, MessagesPlaceholder } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatMessageHistory } from \\\\\"langchain/stores/message/in_memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RunnableSequence } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RunnablePassthrough } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { getBufferString } from \\\\\"@langchain/core/messages\\\\\";\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const summaryModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const summaryPrompt = ChatPromptTemplate.fromTemplate(`\\\\n\",\\n' +\n",
      "      '    \"Progressively summarize the lines of conversation provided, adding onto the previous summary returning a new summary\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"Current summary:\\\\n\",\\n' +\n",
      "      '    \"{summary}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"New lines of conversation:\\\\n\",\\n' +\n",
      "      '    \"{new_lines}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"New summary:\\\\n\",\\n' +\n",
      "      '    \"`); \\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const summaryChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    summaryPrompt,\\\\n\",\\n' +\n",
      "      '    \"    summaryModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const newSummary = await summaryChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"\\\\\",\\\\n\",\\n' +\n",
      "      `    \"    new_lines: \\\\\"I'm 18\\\\\"\\\\n\",\\n` +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(res)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await summaryChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    summary: res,\\\\n\",\\n' +\n",
      "      `    \"    new_lines: \\\\\"I'm male\\\\\"\\\\n\",\\n` +\n",
      "      '    \"})\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const chatModel = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const chatPrompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"system\\\\\", `You are a helpful assistant. Answer all questions to the best of your ability.\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"    Here is the chat history summary:\\\\n\",\\n' +\n",
      "      '    \"    {history_summary}\\\\n\",\\n' +\n",
      "      '    \"    `],\\\\n\",\\n' +\n",
      "      '    \"    [\\\\\"human\\\\\",\\\\\"{input}\\\\\"]\\\\n\",\\n' +\n",
      "      '    \"]);\\\\n\",\\n' +\n",
      "      '    \"let summary = \\\\\"\\\\\"\\\\n\",\\n' +\n",
      "      '    \"const history = new ChatMessageHistory();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        input: new RunnablePassthrough({\\\\n\",\\n' +\n",
      "      '    \"             func: (input) => history.addUserMessage(input)\\\\n\",\\n' +\n",
      "      '    \"        })\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    RunnablePassthrough.assign({\\\\n\",\\n' +\n",
      "      '    \"        history_summary: () => summary\\\\n\",\\n' +\n",
      "      '    \"    }),\\\\n\",\\n' +\n",
      "      '    \"    chatPrompt,\\\\n\",\\n' +\n",
      "      '    \"    chatModel,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser(),\\\\n\",\\n' +\n",
      "      '    \"    new RunnablePassthrough({\\\\n\",\\n' +\n",
      "      '    \"        func: async (input) => {\\\\n\",\\n' +\n",
      "      '    \"            history.addAIChatMessage(input)\\\\n\",\\n' +\n",
      "      '    \"            const messages = await history.getMessages()\\\\n\",\\n' +\n",
      "      '    \"            const new_lines = getBufferString(messages)\\\\n\",\\n' +\n",
      "      '    \"            const newSummary = await summaryChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"                summary,\\\\n\",\\n' +\n",
      "      '    \"                new_lines\\\\n\",\\n' +\n",
      "      '    \"            })\\\\n\",\\n' +\n",
      "      '    \"            console.log(summary, input, messages, new_lines, newSummary)\\\\n\",\\n' +\n",
      "      '    \"            history.clear()\\\\n\",\\n' +\n",
      "      '    \"            summary = newSummary      \\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    })\\\\n\",\\n' +\n",
      "      '    \"])\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chatChain.invoke(\\\\\"我现在饿了\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(summary)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"await chatChain.invoke(\\\\\"我今天想吃方便面\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"co'... 877 more characters,\n",
      "    metadata: {\n",
      "      source: \"memory.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"id\": \"initial_id\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"collapsed\": true,\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:19:55.869080Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:19:54.984792Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { Ollama } from \\\\\"@langchain/community/llms/ollama\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const ollama = new Ollama({\\\\n\",\\n' +\n",
      "      '    \"    baseUrl: \\\\\"http://localhost:11434\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    model: \\\\\"llama3\\\\\"\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const res = await ollama.invoke(\\\\\"tell me a joke\\\\\");\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 2\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T15:19:57.736711Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T15:19:57.735475Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": \"console.log(res)\",\\n' +\n",
      "      '   \"id\": \"52728896be3ad4a6\",\\n' +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      `      \"Here's one:\\\\n\",\\n` +\n",
      "      '      \"\\\\n\",\\n' +\n",
      "      `      \"Why don't eggs tell jokes?\\\\n\",\\n` +\n",
      "      '      \"\\\\n\",\\n' +\n",
      "      '      \"(wait for it...)\\\\n\",\\n' +\n",
      "      '      \"\\\\n\",\\n' +\n",
      "      `      \"Because they'd crack each other up!\\\\n\",\\n` +\n",
      "      '      \"\\\\n\",\\n' +\n",
      "      '      \"Hope that made you smile!\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 3\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"source\": \"\",\\n' +\n",
      "      '   \"id\": \"dc43421b0af77c06\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"codemirror_mode\": {\\n' +\n",
      "      '    \"name\": \"ipython\",\\n' +\n",
      "      '    \"version\": 2\\n' +\n",
      "      \"   },\\n\" +\n",
      "      '   \"file_extension\": \".py\",\\n' +\n",
      "      '   \"mimetype\": \"text/x-python\",\\n' +\n",
      "      '   \"name\": \"python\",\\n' +\n",
      "      '   \"nbconvert_exporter\": \"python\",\\n' +\n",
      "      '   \"pygments_lexer\": \"ipython2\",\\n' +\n",
      "      '   \"version\": \"2.7.6\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 5\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"ollama.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await model.invoke([\\\\n\",\\n' +\n",
      "      '    \"    new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const parser = new StringOutputParser();\\\\n\",\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = model.pipe(parser)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"await chain.invoke([\\\\n\",\\n' +\n",
      "      '    \"    new HumanMessage(\\\\\"Tell me a joke\\\\\")\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { StructuredOutputParser } from \\\\\"langchain/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { PromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const parser = StructuredOutputParser.fromNamesAndDescriptions({\\\\n\",\\n' +\n",
      "      '    \"  answer: \\\\\"用户问题的答案\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  evidence: \\\\\"你回答用户问题所依据的答案\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  confidence: \\\\\"问题答案的可信度评分，格式是百分数\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(parser.getFormatInstructions())\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const prompt = PromptTemplate.fromTemplate(\\\\\"尽可能的回答用的问题 \\\\\\\\n{instructions} \\\\\\\\n{question}\\\\\")\\\\n\",\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(model).pipe(parser)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    question: \\\\\"蒙娜丽莎的作者是谁？是什么时候绘制的\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    instructions: parser.getFormatInstructions()\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"                               \\\\n\",\\n' +\n",
      "      '    \"console.log(res)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { CommaSeparatedListOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const parser = new CommaSeparatedListOutputParser();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(parser.getFormatInstructions())\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const prompt = PromptTemplate.fromTemplate(\\\\\"列出3个 {country} 的着名的互联网公司.\\\\\\\\n{instructions}\\\\\")\\\\n\",\\n' +\n",
      "      '    \"    \\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(model).pipe(parser)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const response = await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    country: \\\\\"America\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    instructions: parser.getFormatInstructions(),\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"response\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { z } from \\\\\"zod\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { StructuredOutputParser, OutputFixingParser } from \\\\\"langchain/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { PromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { HumanMessage } from \\\\\"@langchain/core/messages\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const schema = z.object({\\\\n\",\\n' +\n",
      "      '    \"  answer:  z.string().describe(\\\\\"用户问题的答案\\\\\"),\\\\n\",\\n' +\n",
      "      '    \"  confidence: z.number().min(0).max(100).describe(\\\\\"问题答案的可信度评分，满分 100\\\\\")\\\\n\",\\n' +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const parser = StructuredOutputParser.fromZodSchema(schema);\\\\n\",\\n' +\n",
      "      '    \"const prompt = PromptTemplate.fromTemplate(\\\\\"尽可能的回答用的问题 \\\\\\\\n{instructions} \\\\\\\\n{question}\\\\\")\\\\n\",\\n' +\n",
      "      '    \"//const model = new ChatOpenAI();\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI({\\\\n\",\\n' +\n",
      "      '    \"    configuration: {\\\\n\",\\n' +\n",
      "      '    \"        baseURL: \\\\\"https://blog.sayyou.icu/v1\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chain = prompt.pipe(model).pipe(parser)\\\\n\",\\n' +\n",
      "      '    \"const res = await chain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    question: \\\\\"蒙娜丽莎的作者是谁？是什么时候绘制的\\\\\",\\\\n\",\\n' +\n",
      "      '    \"    instructions: parser.getFormatInstructions()\\\\n\",\\n' +\n",
      "      '    \"})\\\\n\",\\n' +\n",
      "      '    \"                               \\\\n\",\\n' +\n",
      "      '    \"console.log(res)\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const wrongOutput = {\\\\n\",\\n' +\n",
      "      '    \"  \\\\\"answer\\\\\": \\\\\"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  \\\\\"sources\\\\\": \\\\\"90%\\\\\" \\\\n\",\\n' +\n",
      "      '    \"};\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const fixParser = OutputFixingParser.fromLLM(model, parser);\\\\n\",\\n' +\n",
      "      '    \"const output = await fixParser.parse(JSON.stringify(wrongOutput));\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"output\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const wrongOutput = {\\\\n\",\\n' +\n",
      "      '    \"  \\\\\"answer\\\\\": \\\\\"蒙娜丽莎的作者是达芬奇，大约在16世纪初期（1503年至1506年之间）开始绘制。\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  \\\\\"sources\\\\\": \\\\\"-1\\\\\" \\\\n\",\\n' +\n",
      "      '    \"};\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const fixParser = OutputFixingParser.fromLLM(model, parser);\\\\n\",\\n' +\n",
      "      '    \"const output = await fixParser.parse(JSON.stringify(wrongOutput));\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"output\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(fixParser.getFormatInstructions())\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"source\": \"\",\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": null\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"output-parser.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:04:52.771872Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:04:52.702196Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { PromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const greetingPrompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [],\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"hello world\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const formattedGreetingPrompt = await greetingPrompt.format();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedGreetingPrompt);\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"hello world\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 1\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"scrolled\": true,\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:05.297893Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:05.295871Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const personalizedGreetingPrompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"name\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"hello，{name}  {{test}}\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const formattedPersonalizedGreeting = await personalizedGreetingPrompt.format({\\\\n\",\\n' +\n",
      "      '    \"  name: \\\\\"Kai\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedPersonalizedGreeting);\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"hello，Kai  {test}\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 2\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:14.743519Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:14.742510Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const multiVariableGreetingPrompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"timeOfDay\\\\\", \\\\\"name\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"good {timeOfDay}, {name}\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\\\\n\",\\n' +\n",
      "      '    \"  timeOfDay: \\\\\"morning\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  name: \\\\\"Kai\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedMultiVariableGreeting);\\\\n\",\\n' +\n",
      "      '    \"// good morning, Kai\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"good morning, Kai\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 3\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:18.625824Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:18.624391Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const multiVariableGreetingPrompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"timeOfDay\\\\\", \\\\\"name\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"good {timeOfDay}, {name} {{test}}\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const formattedMultiVariableGreeting = await multiVariableGreetingPrompt.format({\\\\n\",\\n' +\n",
      "      '    \"  timeOfDay: \\\\\"morning\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  name: \\\\\"Kai\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedMultiVariableGreeting);\\\\n\",\\n' +\n",
      "      '    \"// good morning, Kai {test}\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"good morning, Kai {test}\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 4\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:21.115108Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:21.111723Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const autoInferTemplate = PromptTemplate.fromTemplate(\\\\\"good {timeOfDay}, {name}\\\\\");\\\\n\",\\n' +\n",
      "      '    \"console.log(autoInferTemplate.inputVariables);\\\\n\",\\n' +\n",
      "      `    \"// ['timeOfDay', 'name']\\\\n\",\\n` +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const formattedAutoInferTemplate = await autoInferTemplate.format({\\\\n\",\\n' +\n",
      "      '    \"  timeOfDay: \\\\\"morning\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  name: \\\\\"Kai\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedAutoInferTemplate)\\\\n\",\\n' +\n",
      "      '    \"// good morning, Kai\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"[ \\\\\"timeOfDay\\\\\", \\\\\"name\\\\\" ]\\\\n\",\\n' +\n",
      "      '      \"good morning, Kai\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 5\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:24.563020Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:24.560833Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const initialPrompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"这是一个{type}，它是{item}。\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"type\\\\\", \\\\\"item\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const partialedPrompt = await initialPrompt.partial({\\\\n\",\\n' +\n",
      "      '    \"  type: \\\\\"工具\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const formattedPrompt = await partialedPrompt.format({\\\\n\",\\n' +\n",
      "      '    \"  item: \\\\\"锤子\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedPrompt);\\\\n\",\\n' +\n",
      "      '    \"// 这是一个工具，它是锤子。\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const formattedPrompt2 = await partialedPrompt.format({\\\\n\",\\n' +\n",
      "      '    \"  item: \\\\\"改锥\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedPrompt2)\\\\n\",\\n' +\n",
      "      '    \"// 这是一个工具，它是改锥。\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"这是一个工具，它是锤子。\\\\n\",\\n' +\n",
      "      '      \"这是一个工具，它是改锥。\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 6\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:28.582460Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:28.555917Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const getCurrentDateStr = () => {\\\\n\",\\n' +\n",
      "      '    \"  return new Date().toLocaleDateString();\\\\n\",\\n' +\n",
      "      '    \"};\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const promptWithDate = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"今天是{date}，{activity}。\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"date\\\\\", \\\\\"activity\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const partialedPromptWithDate = await promptWithDate.partial({\\\\n\",\\n' +\n",
      "      '    \"  date: getCurrentDateStr,\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const formattedPromptWithDate = await partialedPromptWithDate.format({\\\\n\",\\n' +\n",
      "      '    \"  activity: \\\\\"我们去爬山\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedPromptWithDate);\\\\n\",\\n' +\n",
      "      '    \"// 输出: 今天是2023/7/13，我们去爬山。\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"今天是5/24/2024，我们去爬山。\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 7\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:32.877560Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:32.875916Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const getCurrentDateStr = () => {\\\\n\",\\n' +\n",
      "      '    \"  return new Date().toLocaleDateString();\\\\n\",\\n' +\n",
      "      '    \"};\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"function generateGreeting(timeOfDay) {\\\\n\",\\n' +\n",
      "      '    \"  return () => {\\\\n\",\\n' +\n",
      "      '    \"    const date = getCurrentDateStr()\\\\n\",\\n' +\n",
      "      '    \"    switch (timeOfDay) {\\\\n\",\\n' +\n",
      "      `    \"      case 'morning':\\\\n\",\\n` +\n",
      "      `    \"        return date + ' 早上好';\\\\n\",\\n` +\n",
      "      `    \"      case 'afternoon':\\\\n\",\\n` +\n",
      "      `    \"        return date + ' 下午好';\\\\n\",\\n` +\n",
      "      `    \"      case 'evening':\\\\n\",\\n` +\n",
      "      `    \"        return date + ' 晚上好';\\\\n\",\\n` +\n",
      "      '    \"      default:\\\\n\",\\n' +\n",
      "      `    \"        return date + ' 你好';\\\\n\",\\n` +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"  };\\\\n\",\\n' +\n",
      "      '    \"}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const prompt = new PromptTemplate({\\\\n\",\\n' +\n",
      "      '    \"  template: \\\\\"{greeting}!\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  inputVariables: [\\\\\"greeting\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      `    \"const currentTimeOfDay = 'afternoon';\\\\n\",\\n` +\n",
      "      '    \"const partialPrompt = await prompt.partial({\\\\n\",\\n' +\n",
      "      '    \"  greeting: generateGreeting(currentTimeOfDay),\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const formattedPrompt = await partialPrompt.format();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(formattedPrompt);\\\\n\",\\n' +\n",
      "      '    \"// 输出: 3/21/2024 下午好!\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"name\": \"stdout\",\\n' +\n",
      "      '     \"output_type\": \"stream\",\\n' +\n",
      "      '     \"text\": [\\n' +\n",
      "      '      \"5/24/2024 下午好!\\\\n\"\\n' +\n",
      "      \"     ]\\n\" +\n",
      "      \"    }\\n\" +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"execution_count\": 8\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:35.904776Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:35.900294Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { SystemMessagePromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const translateInstructionTemplate = SystemMessagePromptTemplate.fromTemplate(\\\\\"你是一个专业的翻译员，你的任务是将文本从{source_lang}翻译成{target_lang}。\\\\\");\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 9\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:41.269308Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:41.263686Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { HumanMessagePromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const userQuestionTemplate = HumanMessagePromptTemplate.fromTemplate(\\\\\"请翻译这句话：{text}\\\\\")\\\\n\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 10\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:42.684385Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:42.679798Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatPromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const chatPrompt = ChatPromptTemplate.fromMessages([\\\\n\",\\n' +\n",
      "      '    \"  translateInstructionTemplate,\\\\n\",\\n' +\n",
      "      '    \"  userQuestionTemplate,\\\\n\",\\n' +\n",
      "      '    \"]);\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"execution_count\": 11\\n' +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"metadata\": {\\n' +\n",
      "      '    \"ExecuteTime\": {\\n' +\n",
      "      '     \"end_time\": \"2024-05-23T17:05:43.907124Z\",\\n' +\n",
      "      '     \"start_time\": \"2024-05-23T17:05:43.904427Z\"\\n' +\n",
      "      \"    }\\n\" +\n",
      "      \"   },\\n\" +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const formattedChatPrompt = await chatPrompt.formatMessages({\\\\n\",\\n' +\n",
      "      '    \"  source_lang: \\\\\"中文\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  target_lang: \\\\\"法语\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  text: \\\\\"你好，世界\\\\\",\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"formattedChatPrompt\"\\n' +\n",
      "      \"   ],\\n\" +\n",
      "      '   \"outputs\": [\\n' +\n",
      "      \"    {\\n\" +\n",
      "      '     \"data\": {\\n' +\n",
      "      '      \"text/plain\": [\\n' +\n",
      "      '       \"[\\\\n\",\\n' +\n",
      "      '       \"  SystemMessage {\\\\n\",\\n' +\n",
      "      '       \"    lc_serializable: \\\\u001B[33mtrue\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"    lc_kwargs: {\\\\n\",\\n' +\n",
      "      '       \"      content: \\\\u001B[32m\\\\\"你是一个专业的翻译员，你的任务是将文本从中文翻译成法语。\\\\\"\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"      additional_kwargs: {},\\\\n\",\\n' +\n",
      "      '       \"      response_metadata: {}\\\\n\",\\n' +\n",
      "      '       \"    },\\\\n\",\\n' +\n",
      "      '       \"    lc_namespace: [ \\\\u001B[32m\\\\\"langchain_core\\\\\"\\\\u001B[39m, \\\\u001B[32m\\\\\"messages\\\\\"\\\\u001B[39m ],\\\\n\",\\n' +\n",
      "      '       \"    content: \\\\u001B[32m\\\\\"你是一个专业的翻译员，你的任务是将文本从中文翻译成法语。\\\\\"\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"    name: \\\\u001B[90mundefined\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"    additional_kwargs: {},\\\\n\",\\n' +\n",
      "      '       \"    response_metadata: {}\\\\n\",\\n' +\n",
      "      '       \"  },\\\\n\",\\n' +\n",
      "      '       \"  HumanMessage {\\\\n\",\\n' +\n",
      "      '       \"    lc_serializable: \\\\u001B[33mtrue\\\\u001B[39m,\\\\n\",\\n' +\n",
      "      '       \"    lc_kwargs: {\\\\n\",\\n' +\n",
      "      '       \"      content: \\\\u001B[32m\\\\\"'... 5121 more characters,\n",
      "    metadata: {\n",
      "      source: \"prompt-template.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { TextLoader } from \\\\\"langchain/document_loaders/fs/text\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const loader = new TextLoader(\\\\\"data/qiu.txt\\\\\");\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RecursiveCharacterTextSplitter } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitter = new RecursiveCharacterTextSplitter({\\\\n\",\\n' +\n",
      "      '    \"    chunkSize: 500,\\\\n\",\\n' +\n",
      "      '    \"    chunkOverlap: 100,\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitDocs = await splitter.splitDocuments(docs);\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(splitDocs[4])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(splitDocs[4].pageContent)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { OpenAIEmbeddings } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const embeddings = new OpenAIEmbeddings();\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { MemoryVectorStore } from \\\\\"langchain/vectorstores/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const vectorstore = new MemoryVectorStore(embeddings);\\\\n\",\\n' +\n",
      "      '    \"await vectorstore.addDocuments(splitDocs);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const retriever = vectorstore.asRetriever(2)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await retriever.invoke(\\\\\"原文中，谁提出了宏原子的假设？并详细介绍给我宏原子假设的理论\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RunnableSequence } from \\\\\"@langchain/core/runnables\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { Document } from \\\\\"@langchain/core/documents\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const convertDocsToString = (documents: Document[]): string => {\\\\n\",\\n' +\n",
      "      '    \"     return documents.map((document) => document.pageContent).join(\\\\\"\\\\\\\\n\\\\\")\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"const contextRetriverChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    (input) => input.question,\\\\n\",\\n' +\n",
      "      '    \"    retriever,\\\\n\",\\n' +\n",
      "      '    \"    convertDocsToString\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const result = await contextRetriverChain.invoke({ question: \\\\\"原文中，谁提出了宏原子的假设？并详细介绍给我宏原子假设的理论\\\\\"})\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(result)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatPromptTemplate } from \\\\\"@langchain/core/prompts\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const TEMPLATE = `\\\\n\",\\n' +\n",
      "      '    \"你是一个熟读刘慈欣的《球状闪电》的终极原著党，精通根据作品原文详细解释和回答问题，你在回答时会引用作品原文。\\\\n\",\\n' +\n",
      "      '    \"并且回答时仅根据原文，尽可能回答用户问题，如果原文中没有相关内容，你可以回答“原文中没有相关内容”，\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"以下是原文中跟用户回答相关的内容：\\\\n\",\\n' +\n",
      "      '    \"{context}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"现在，你需要基于原文，回答以下问题：\\\\n\",\\n' +\n",
      "      '    \"{question}`;\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const prompt = ChatPromptTemplate.fromTemplate(\\\\n\",\\n' +\n",
      "      '    \"    TEMPLATE\\\\n\",\\n' +\n",
      "      '    \");\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { ChatOpenAI } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const model = new ChatOpenAI();\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { StringOutputParser } from \\\\\"@langchain/core/output_parsers\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const ragChain = RunnableSequence.from([\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        context: contextRetriverChain,\\\\n\",\\n' +\n",
      "      '    \"        question: (input) => input.question,\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    prompt,\\\\n\",\\n' +\n",
      "      '    \"    model,\\\\n\",\\n' +\n",
      "      '    \"    new StringOutputParser()\\\\n\",\\n' +\n",
      "      '    \"])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const answer = await ragChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    question: \\\\\"什么是球状闪电\\\\\"\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"  \\\\n\",\\n' +\n",
      "      '    \"  console.log(answer);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const answer = await ragChain.invoke({\\\\n\",\\n' +\n",
      "      '    \"    question: \\\\\"详细描述原文中有什么跟直升机相关的场景\\\\\"\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(answer);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"rag.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { TextLoader } from \\\\\"langchain/document_loaders/fs/text\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const loader = new TextLoader(\\\\\"data/kong.txt\\\\\");\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RecursiveCharacterTextSplitter } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitter = new RecursiveCharacterTextSplitter({\\\\n\",\\n' +\n",
      "      '    \"    chunkSize: 64,\\\\n\",\\n' +\n",
      "      '    \"    chunkOverlap: 0,\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitDocs = await splitter.splitDocuments(docs);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const splitter = new RecursiveCharacterTextSplitter({\\\\n\",\\n' +\n",
      "      '    \"    chunkSize: 64,\\\\n\",\\n' +\n",
      "      '    \"    chunkOverlap: 16,\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitDocs = await splitter.splitDocuments(docs);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"splitDocs\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { SupportedTextSplitterLanguages } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(SupportedTextSplitterLanguages); \"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { RecursiveCharacterTextSplitter } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const js = `\\\\n\",\\n' +\n",
      "      '    \"function myFunction(name,job){\\\\n\",\\n' +\n",
      "      '    \"\\\\tconsole.log(\\\\\"Welcome \\\\\" + name + \\\\\", the \\\\\" + job);\\\\n\",\\n' +\n",
      "      '    \"}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      `    \"myFunction('Harry Potter','Wizard')\\\\n\",\\n` +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"function forFunction(){\\\\n\",\\n' +\n",
      "      '    \"\\\\tfor (let i=0; i<5; i++){\\\\n\",\\n' +\n",
      "      '    \"        console.log(\\\\\"这个数字是\\\\\" + i)\\\\n\",\\n' +\n",
      "      '    \"\\\\t}\\\\n\",\\n' +\n",
      "      '    \"}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"forFunction()\\\\n\",\\n' +\n",
      "      '    \"`;\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitter = RecursiveCharacterTextSplitter.fromLanguage(\\\\\"js\\\\\", {\\\\n\",\\n' +\n",
      "      '    \"  chunkSize: 64,\\\\n\",\\n' +\n",
      "      '    \"  chunkOverlap: 0,\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"const jsOutput = await splitter.createDocuments([js]);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"jsOutput\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { TokenTextSplitter } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const text = \\\\\"I stand before you today the representative of a family in grief, in a country in mourning before a world in shock.\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitter = new TokenTextSplitter({\\\\n\",\\n' +\n",
      "      '    \"  encodingName: \\\\\"gpt2\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  chunkSize: 10,\\\\n\",\\n' +\n",
      "      '    \"  chunkOverlap: 0,\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const docs = await splitter.createDocuments([text]);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"docs\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"splitter.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import OpenAI from \\\\\"openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const openai = new OpenAI({\\\\n\",\\n' +\n",
      "      '    \"    apiKey: env[\\\\\"AZURE_OPENAI_API_KEY\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    baseURL: `https://${env[\\\\\"AZURE_OPENAI_API_INSTANCE_NAME\\\\\"]}.openai.azure.com/openai/deployments/${env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"]}`,\\\\n\",\\n' +\n",
      "      `    \"    defaultQuery: { 'api-version':  env[\\\\\"AZURE_OPENAI_API_VERSION\\\\\"] },\\\\n\",\\n` +\n",
      "      `    \"    defaultHeaders: { 'api-key': env[\\\\\"AZURE_OPENAI_API_KEY\\\\\"] },\\\\n\",\\n` +\n",
      "      '    \"});\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const result = await openai.chat.completions.create({\\\\n\",\\n' +\n",
      "      `    \"    // model: 'gpt-3.5-turbo',\\\\n\",\\n` +\n",
      "      '    \"    model: env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"],\\\\n\",\\n' +\n",
      "      `    \"    messages: [{ role: 'user', content: 'Say hello!' }],\\\\n\",\\n` +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"  console.log(result.choices[0]!.message?.content);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"function getCurrentWeather({ location, unit=\\\\\"fahrenheit\\\\\"}){\\\\n\",\\n' +\n",
      "      '    \"   const  weather_info = {\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"location\\\\\": location,\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"temperature\\\\\": \\\\\"72\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"unit\\\\\": unit,\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"forecast\\\\\": [\\\\\"sunny\\\\\", \\\\\"windy\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"    return JSON.stringify(weather_info);\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const tools = [\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"      type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"      function: {\\\\n\",\\n' +\n",
      "      '    \"        name: \\\\\"getCurrentWeather\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        description: \\\\\"Get the current weather in a given location\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        parameters: {\\\\n\",\\n' +\n",
      "      '    \"          type: \\\\\"object\\\\\",\\\\n\",\\n' +\n",
      "      '    \"          properties: {\\\\n\",\\n' +\n",
      "      '    \"            location: {\\\\n\",\\n' +\n",
      "      '    \"              type: \\\\\"string\\\\\",\\\\n\",\\n' +\n",
      "      '    \"              description: \\\\\"The city and state, e.g. San Francisco, CA\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            },\\\\n\",\\n' +\n",
      "      '    \"            unit: { \\\\n\",\\n' +\n",
      "      '    \"              type: \\\\\"string\\\\\", \\\\n\",\\n' +\n",
      "      '    \"              enum: [\\\\\"celsius\\\\\", \\\\\"fahrenheit\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"              description: \\\\\"The unit of temperature\\\\\"\\\\n\",\\n' +\n",
      "      '    \"            },\\\\n\",\\n' +\n",
      "      '    \"          },\\\\n\",\\n' +\n",
      "      '    \"          required: [\\\\\"location\\\\\", \\\\\"unit\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"        },\\\\n\",\\n' +\n",
      "      '    \"      },\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"]\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \" const messages = [\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"role\\\\\": \\\\\"user\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        // \\\\\"content\\\\\": \\\\\"北京的天气怎么样\\\\\"\\\\n\",\\n' +\n",
      "      `    \"        \\\\\"content\\\\\": \\\\\"What's the weather like in Redmond?\\\\\"\\\\n\",\\n` +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"]\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const result = await openai.chat.completions.create({\\\\n\",\\n' +\n",
      "      `    \"    // model: 'gpt-3.5-turbo',\\\\n\",\\n` +\n",
      "      '    \"    model: env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    messages,\\\\n\",\\n' +\n",
      "      '    \"    tools\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"  console.log(result);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"result.choices[0]\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const messages = [\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"role\\\\\": \\\\\"user\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        \\\\\"content\\\\\": \\\\\"你好\\\\\"\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"]\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const result = await openai.chat.completions.create({\\\\n\",\\n' +\n",
      "      `    \"    // model: 'gpt-3.5-turbo',\\\\n\",\\n` +\n",
      "      '    \"    model: env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    messages,\\\\n\",\\n' +\n",
      "      '    \"    tools,\\\\n\",\\n' +\n",
      "      '    \"    tool_choice: {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"           name: \\\\\"getCurrentWeather\\\\\"\\\\n\",\\n' +\n",
      "      '    \"        }\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"  });\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const functions = {\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"getCurrentWeather\\\\\": getCurrentWeather\\\\n\",\\n' +\n",
      "      '    \"  }\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const functionInfo = result.choices[0].message.tool_calls[0].function\\\\n\",\\n' +\n",
      "      '    \"const functionName = functionInfo.name;\\\\n\",\\n' +\n",
      "      '    \"const functionParams = functionInfo.arguments\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const functionResult = functions[functionName](functionParams);\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(functionResult);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"function getCurrentTime({ format = \\\\\"iso\\\\\" } = {}) {\\\\n\",\\n' +\n",
      "      '    \"    let currentTime;\\\\n\",\\n' +\n",
      "      '    \"    switch (format) {\\\\n\",\\n' +\n",
      "      '    \"        case \\\\\"iso\\\\\":\\\\n\",\\n' +\n",
      "      '    \"            currentTime = new Date().toISOString();\\\\n\",\\n' +\n",
      "      '    \"            break;\\\\n\",\\n' +\n",
      "      '    \"        case \\\\\"locale\\\\\":\\\\n\",\\n' +\n",
      "      '    \"            currentTime = new Date().toLocaleString();\\\\n\",\\n' +\n",
      "      '    \"            break;\\\\n\",\\n' +\n",
      "      '    \"        default:\\\\n\",\\n' +\n",
      "      '    \"            currentTime = new Date().toString();\\\\n\",\\n' +\n",
      "      '    \"            break;\\\\n\",\\n' +\n",
      "      '    \"    }\\\\n\",\\n' +\n",
      "      '    \"    return currentTime;\\\\n\",\\n' +\n",
      "      '    \"}\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const tools = [\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"            name: \\\\\"getCurrentTime\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            description: \\\\\"Get the current time in a given format\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            parameters: {\\\\n\",\\n' +\n",
      "      '    \"                type: \\\\\"object\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                properties: {\\\\n\",\\n' +\n",
      "      '    \"                    format: {\\\\n\",\\n' +\n",
      "      '    \"                        type: \\\\\"string\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                        enum: [\\\\\"iso\\\\\", \\\\\"locale\\\\\", \\\\\"string\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"                        description: \\\\\"The format of the time, e.g. iso, locale, string\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                    },\\\\n\",\\n' +\n",
      "      '    \"                },\\\\n\",\\n' +\n",
      "      '    \"                required: [],\\\\n\",\\n' +\n",
      "      '    \"            },\\\\n\",\\n' +\n",
      "      '    \"        },\\\\n\",\\n' +\n",
      "      '    \"    },\\\\n\",\\n' +\n",
      "      '    \"    {\\\\n\",\\n' +\n",
      "      '    \"        type: \\\\\"function\\\\\",\\\\n\",\\n' +\n",
      "      '    \"        function: {\\\\n\",\\n' +\n",
      "      '    \"          name: \\\\\"getCurrentWeather\\\\\",\\\\n\",\\n' +\n",
      "      '    \"          description: \\\\\"Get the current weather in a given location\\\\\",\\\\n\",\\n' +\n",
      "      '    \"          parameters: {\\\\n\",\\n' +\n",
      "      '    \"            type: \\\\\"object\\\\\",\\\\n\",\\n' +\n",
      "      '    \"            properties: {\\\\n\",\\n' +\n",
      "      '    \"              location: {\\\\n\",\\n' +\n",
      "      '    \"                type: \\\\\"string\\\\\",\\\\n\",\\n' +\n",
      "      '    \"                description: \\\\\"The city and state, e.g. San Francisco, CA\\\\\",\\\\n\",\\n' +\n",
      "      '    \"              },\\\\n\",\\n' +\n",
      "      '    \"              unit: { type: \\\\\"string\\\\\", enum: [\\\\\"celsius\\\\\", \\\\\"fahrenheit\\\\\"] },\\\\n\",\\n' +\n",
      "      '    \"            },\\\\n\",\\n' +\n",
      "      '    \"            required: [\\\\\"location\\\\\", \\\\\"unit\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"          },\\\\n\",\\n' +\n",
      "      '    \"        },\\\\n\",\\n' +\n",
      "      '    \"      }\\\\n\",\\n' +\n",
      "      '    \"];\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const messages = [\\\\n\",\\n' +\n",
      "      '    \"    { role: \\\\\"user\\\\\", content: \\\\\" 上海 新疆 这三个城市的天气如何?\\\\\" },\\\\n\",\\n' +\n",
      "      '    \"]\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const result = await openai.chat.completions.create({\\\\n\",\\n' +\n",
      "      `    \"    // model: 'gpt-3.5-turbo',\\\\n\",\\n` +\n",
      "      '    \"    model: env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"    messages,\\\\n\",\\n' +\n",
      "      '    \"    tools\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"result.choices[0]\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"messages.push(result.choices[0].message)\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const functions = {\\\\n\",\\n' +\n",
      "      '    \"    \\\\\"getCurrentWeather\\\\\": getCurrentWeather\\\\n\",\\n' +\n",
      "      '    \"  }\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const cell = result.choices[0].message.tool_calls[0]\\\\n\",\\n' +\n",
      "      '    \"const functionInfo = cell.function\\\\n\",\\n' +\n",
      "      '    \"const functionName = functionInfo.name;\\\\n\",\\n' +\n",
      "      '    \"const functionParams = functionInfo.arguments\\\\n\",\\n' +\n",
      "      '    \"const functionResult = functions[functionName](functionParams);\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"console.log(messages);\\\\n\",\\n' +\n",
      "      '    \"messages.push({\\\\n\",\\n' +\n",
      "      '    \"  tool_call_id: cell.id,\\\\n\",\\n' +\n",
      "      '    \"  role: \\\\\"tool\\\\\",\\\\n\",\\n' +\n",
      "      '    \"  name: functionName,\\\\n\",\\n' +\n",
      "      '    \"  content: functionResult,\\\\n\",\\n' +\n",
      "      '    \"}); \\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const response = await openai.chat.completions.create({\\\\n\",\\n' +\n",
      "      `    \"  // model: 'gpt-3.5-turbo',\\\\n\",\\n` +\n",
      "      '    \"  model: env[\\\\\"AZURE_OPENAI_API_DEPLOYMENT_NAME\\\\\"],\\\\n\",\\n' +\n",
      "      '    \"  messages,\\\\n\",\\n' +\n",
      "      '    \"});\\\\n\",\\n' +\n",
      "      '    \"console.log(response);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"response.choices[0].message\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"messages\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 2\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"tool-lesson.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  },\n",
      "  Document {\n",
      "    pageContent: \"{\\n\" +\n",
      "      ' \"cells\": [\\n' +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { load } from \\\\\"dotenv\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const env = await load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const process = {\\\\n\",\\n' +\n",
      "      '    \"    env\\\\n\",\\n' +\n",
      "      '    \"}\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { TextLoader } from \\\\\"langchain/document_loaders/fs/text\\\\\";\\\\n\",\\n' +\n",
      "      '    \"import { RecursiveCharacterTextSplitter } from \\\\\"langchain/text_splitter\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const loader = new TextLoader(\\\\\"data/kong.txt\\\\\");\\\\n\",\\n' +\n",
      "      '    \"const docs = await loader.load();\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitter = new RecursiveCharacterTextSplitter({\\\\n\",\\n' +\n",
      "      '    \"    chunkSize: 100,\\\\n\",\\n' +\n",
      "      '    \"    chunkOverlap: 20,\\\\n\",\\n' +\n",
      "      '    \"  });\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const splitDocs = await splitter.splitDocuments(docs);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"splitDocs\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"console.log(splitDocs[0])\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { OpenAIEmbeddings } from \\\\\"@langchain/openai\\\\\";\\\\n\",\\n' +\n",
      "      '    \"const embeddings = new OpenAIEmbeddings()\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const res = await embeddings.embedQuery(splitDocs[0].pageContent)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"import { MemoryVectorStore } from \\\\\"langchain/vectorstores/memory\\\\\";\\\\n\",\\n' +\n",
      "      '    \"\\\\n\",\\n' +\n",
      "      '    \"const vectorstore = new MemoryVectorStore(embeddings);\\\\n\",\\n' +\n",
      "      '    \"await vectorstore.addDocuments(splitDocs);\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const retriever = vectorstore.asRetriever(2)\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await retriever.invoke(\\\\\"茴香豆是做什么用的\\\\\")\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"res\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await retriever.invoke(\\\\\"下酒菜一般是什么？\\\\\")\\\\n\",\\n' +\n",
      "      '    \"res\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": [\\n' +\n",
      "      '    \"const res = await retriever.invoke(\\\\\"孔乙己用什么谋生？\\\\\")\\\\n\",\\n' +\n",
      "      '    \"res\"\\n' +\n",
      "      \"   ]\\n\" +\n",
      "      \"  },\\n\" +\n",
      "      \"  {\\n\" +\n",
      "      '   \"cell_type\": \"code\",\\n' +\n",
      "      '   \"execution_count\": null,\\n' +\n",
      "      '   \"metadata\": {},\\n' +\n",
      "      '   \"outputs\": [],\\n' +\n",
      "      '   \"source\": []\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" ],\\n\" +\n",
      "      ' \"metadata\": {\\n' +\n",
      "      '  \"kernelspec\": {\\n' +\n",
      "      '   \"display_name\": \"Deno\",\\n' +\n",
      "      '   \"language\": \"typescript\",\\n' +\n",
      "      '   \"name\": \"deno\"\\n' +\n",
      "      \"  },\\n\" +\n",
      "      '  \"language_info\": {\\n' +\n",
      "      '   \"file_extension\": \".ts\",\\n' +\n",
      "      '   \"mimetype\": \"text/x.typescript\",\\n' +\n",
      "      '   \"name\": \"typescript\",\\n' +\n",
      "      '   \"nb_converter\": \"script\",\\n' +\n",
      "      '   \"pygments_lexer\": \"typescript\",\\n' +\n",
      "      '   \"version\": \"5.3.3\"\\n' +\n",
      "      \"  }\\n\" +\n",
      "      \" },\\n\" +\n",
      "      ' \"nbformat\": 4,\\n' +\n",
      "      ' \"nbformat_minor\": 4\\n' +\n",
      "      \"}\\n\",\n",
      "    metadata: {\n",
      "      source: \"vector-store.ipynb\",\n",
      "      repository: \"https://github.com/zhaomo08/langchainjs-juejin\",\n",
      "      branch: \"main\"\n",
      "    }\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "console.log(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:08.989153Z",
     "start_time": "2024-05-26T04:29:08.899775Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[33m18\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs.length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Module: null prototype] {\n",
       "  contains: \u001b[36m[Function: contains]\u001b[39m,\n",
       "  decodeStream: \u001b[36m[Function: decodeStream]\u001b[39m,\n",
       "  fromURL: \u001b[36m[AsyncFunction: fromURL]\u001b[39m,\n",
       "  load: \u001b[36m[Function: load]\u001b[39m,\n",
       "  loadBuffer: \u001b[36m[Function: loadBuffer]\u001b[39m,\n",
       "  merge: \u001b[36m[Function: merge]\u001b[39m,\n",
       "  stringStream: \u001b[36m[Function: stringStream]\u001b[39m\n",
       "}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import \"cheerio\";\n",
    "import { CheerioWebBaseLoader } from \"langchain/document_loaders/web/cheerio\";\n",
    "\n",
    "const loader = new CheerioWebBaseLoader(\n",
    "  \"https://kaiyi.cool/blog/github-copilot\",\n",
    "  {\n",
    "    selector: \"h3\",\n",
    "  }\n",
    ");\n",
    "\n",
    "const docs = await loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:08.997058Z",
     "start_time": "2024-05-26T04:29:08.996445Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0. 一些基础信息1. 基本使用思路2.变量命名3. 代码速读，代码精读，加注释解析，寻找修改项4. 代码改写，用 xx 库实现整体逻辑5. ai-native 的开发方式6. 报错解析7. 解释 review message8. 提高代码质量，设计优化9. 灵活使用 cmd+i10. 写 commit message11. 基础脚手架、基础 poc12. 中间插入一些唠叨13. llm as doc/search14. 碎碎念15. vsc plugin 开发\n"
     ]
    }
   ],
   "source": [
    "console.log(docs[0].pageContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:09.967410Z",
     "start_time": "2024-05-26T04:29:09.003942Z"
    }
   },
   "outputs": [],
   "source": [
    "import { load } from \"dotenv\";\n",
    "const env = await load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-26T04:29:09.974789Z",
     "start_time": "2024-05-26T04:29:09.974388Z"
    }
   },
   "outputs": [],
   "source": [
    "import { SerpAPILoader } from \"langchain/document_loaders/web/serpapi\";\n",
    "\n",
    "const apiKey = env[\"SERP_KEY\"]\n",
    "const question = \"什么 github copliot\"\n",
    "const loader = new SerpAPILoader({ q: question, apiKey });\n",
    "const docs = await loader.load();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"position\":1,\"title\":\"什么是GitHub Copilot？ - GitHub 文档\",\"link\":\"https://docs.github.com/zh/copilot/about-github-copilot/what-is-github-copilot\",\"redirect_link\":\"https://www.google.com/url?sa=t&source=web&rct=j&opi=89978449&url=https://docs.github.com/zh/copilot/about-github-copilot/what-is-github-copilot&ved=2ahUKEwi1547ShOKNAxXuAjQIHcx9HbMQFnoECBsQAQ\",\"displayed_link\":\"https://docs.github.com › copilot\",\"favicon\":\"https://serpapi.com/searches/68459e43526c488717ae8d74/images/82277c65fb25b02675bdb085dc6a1332ae409164795d97236ae0a852bef5c20c.png\",\"snippet\":\"GitHub Copilot is an AI coding assistant that helps you write code faster and with less effort, allowing you to focus more energy on problem solving and ...\",\"snippet_highlighted_words\":[\"an AI coding assistant\"],\"source\":\"GitHub Docs\"}\n"
     ]
    }
   ],
   "source": [
    "console.log(docs[1].pageContent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Deno",
   "language": "typescript",
   "name": "deno"
  },
  "language_info": {
   "codemirror_mode": "typescript",
   "file_extension": ".ts",
   "mimetype": "text/x.typescript",
   "name": "typescript",
   "nbconvert_exporter": "script",
   "pygments_lexer": "typescript",
   "version": "5.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
